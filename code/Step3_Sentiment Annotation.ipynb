{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc22c3cf-46ae-43fe-8ab4-b0e019d78e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "import glob \n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f2e0d-478e-4ada-b6b0-8b8f2ae0634a",
   "metadata": {},
   "source": [
    "# Annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438de354-f955-450a-9c83-01b5568fd9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/cluster/home/hlee37/git/gutenberg/openai_token.txt', 'r') as file:\n",
    "    oa_api_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14350766-b817-4a2e-8c9b-784e3e44ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = oa_api_key\n",
    "OpenAI.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0618e91c-7484-4232-9e5f-f0550a510d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences_with_gpt(sentences, model=\"gpt-4.1-mini\", batch_size=5, sleep_time=10):\n",
    "  labeled = []\n",
    "  for i in range(0, len(sentences), batch_size):\n",
    "    batch = sentences[i:i+batch_size]\n",
    "    batch_str = \"\\n\".join([f\"{i + j + 1}. {s}\" for j, s in enumerate(batch)])\n",
    "\n",
    "    instructions = [{\n",
    "            \"role\": \"developer\", \"content\": developer_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": f\"Sentences:\\n{batch_str}\"\n",
    "        }]\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "          model=model,\n",
    "          input=instructions,\n",
    "        )\n",
    "\n",
    "        output  = response.output_text\n",
    "        labeled.append((batch, output))\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"error at batch {i}: {e}\")\n",
    "      continue\n",
    "\n",
    "    print(f\"Finished batch {i//batch_size + 1}\")\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "  return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3c6519-ebd9-4702-ba89-aa807f6927e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns to parse from file exception at /cluster/home/hlee37/git/gutenberg/phase2/final/15_Major Warburton.csv\n",
      "No columns to parse from file exception at /cluster/home/hlee37/git/gutenberg/phase2/final/28_Surveyor General Lewis.csv\n",
      "No columns to parse from file exception at /cluster/home/hlee37/git/gutenberg/phase2/final/30_Winnecke.csv\n",
      "No columns to parse from file exception at /cluster/home/hlee37/git/gutenberg/phase2/final/33_F. Hann.csv\n",
      "\n",
      "Combined DataFrame:\n",
      "                                            sentence  predicted_class\n",
      "0  Here our dogs ran a native dog, but did not ki...                1\n",
      "1  Wednesday, the25th August.-The two absentees d...                1\n",
      "2  Next morning, however, just when we were looki...                1\n",
      "3  They had continued down the creek without asce...                1\n",
      "4  They now returned and camped on Monday night a...                1\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/cluster/home/hlee37/git/gutenberg/phase2/final' # Replace with your actual folder path\n",
    "labled_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "all_dataframes = []\n",
    "for file in labled_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        all_dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"{e} exception at {file}\")\n",
    "        \n",
    "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "print(\"\\nCombined DataFrame:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554ce414-c4dc-4084-ad79-05adbf89031f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636992, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a5518f-411f-4da5-9a2e-7f2732993fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = combined_df['sentence'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c475e0b-b0aa-41a6-9e2d-94465b71dcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here our dogs ran a native dog, but did not kill him.',\n",
       " 'Wednesday, the25th August.-The two absentees did not come up to the camp on Sunday evening nor during the forenoon on Monday; I consequently supposed that a serious accident had happened either to Mr Bunce or to Wommai, and resolved to return to the creek we had left, to ascertain in what direction they had gone.',\n",
       " 'Next morning, however, just when we were looking out for our horses, they arrived.',\n",
       " \"They had continued down the creek without ascertaining the direction of our tracks; they had come to the junction of our creek with a very large one; had found three fresh horse-tracks, and supposing them our's had followed them until late at night; they had crossed the large creek, to which we had come on Sunday; next day they had still continued and had considered that the mule-tracks were wanting, but foolishly supposed that the natives had rushed us.\",\n",
       " 'They now returned and camped on Monday night again at the little creek where they had lost us.',\n",
       " 'Next morning they had come on our returning tracks and had followed them to the camp; they had seen a great number of natives, and had spoken with some of them; they had seen the little gin with the white patch on the neck, who passed our camp in going up to the Bunya Bunya.',\n",
       " \"The natives, whose fires were burning all about, and whose cooees and tomahawks we had heard in Sunday Camp, had followed those tracks which we supposed to be Archer's and Chauvel's, 2 miles below the junction of Sunday Creek with the supposed Dogwood Creek, and struck off to the westward, the creek turning a little to the southward.\",\n",
       " 'We were encamped for a short time, and the fat cake not quite ready, when two natives walked boldly up after having cooeed and received our cooee in return.',\n",
       " 'I gave each of them three brass buttons, to show our friendly intentions, and gave them to understand that we were to sleep one night and then continue to the westward.',\n",
       " 'We parted good friends, thought Mr. Bunce told me that he heard them talking near our waterhole-they came perhaps there to fetch water.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63abccb-00f8-4fe3-a7c4-a9392bcff119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 10000 sentences from 636992\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(50)\n",
    "\n",
    "mask_size = 10000\n",
    "mask = np.full(len(sentences), False)\n",
    "mask[:mask_size] = True\n",
    "\n",
    "np.random.shuffle(mask)\n",
    "\n",
    "sample_sentences = [s for s, keep in zip(sentences, mask) if keep]\n",
    "print(f\"‚úÖ Extracted {len(sample_sentences)} sentences from {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5547d1-2480-40f7-a226-dada36aee06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling (if required)\n",
    "\n",
    "# np.random.seed(50)\n",
    "\n",
    "# mask_size = 5000\n",
    "# mask = np.full(len(lable_sentences), False)\n",
    "# mask[:mask_size] = True\n",
    "\n",
    "# np.random.shuffle(mask)\n",
    "\n",
    "# sample_sentences = [s for s, keep in zip(lable_sentences, mask) if keep]\n",
    "# print(f\"‚úÖ Extracted {len(sample_sentences)} sentences from book3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ccd28b5-553c-4161-a0e4-ea870eb22c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You are a helpful research assistant labeling historical sentences from explorer diaries. Your task is to assign one of three sentiment labels to each sentence that was previously identified as describing a relationship or interaction between **Europeans** (e.g., settlers, colonists, explorers) and **Australian Aboriginal people** (e.g., Indigenous people, natives, blackfellows, tribes).\n",
    "\n",
    "### üîç Label each sentence using one of:\n",
    "- **positive**: the interaction is friendly, cooperative, compassionate, or shows mutual respect.\n",
    "- **negative**: the interaction is hostile, fearful, violent, coercive, dismissive, or emotionally painful.\n",
    "- **na**: the sentence was incorrectly marked as a relationship. It **does not actually describe an interaction** between the two groups.\n",
    "\n",
    "‚ö†Ô∏è IMPORTANT:\n",
    "- Focus on **emotionally meaningful interactions** ‚Äî these are most useful for sentiment analysis.\n",
    "- Label only what the sentence *clearly* expresses. Do not infer emotions that aren't stated or strongly implied.\n",
    "- \"na\" should be used for sentences that mention Aboriginal people or Europeans but **lack any interaction or shared event**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Examples\n",
    "\n",
    "Sentence: \"I gave them what Fish we had, some fish Hooks, Twine and a Tomahawk, they appeared glad to get from us.\"\n",
    "Label: positive  \n",
    "Reason: Friendly and generous exchange; clear mutual goodwill.\n",
    "\n",
    "Sentence: \"They did not see us until we surprised them: there were only two Women and four Children, the poor Creatures trembled and fell down with fright.\"\n",
    "Label: negative  \n",
    "Reason: The Aboriginal people responded with visible fear ‚Äî an emotionally intense encounter.\n",
    "\n",
    "Sentence: \"We have not yet seen any Natives but can see their late Tracks.\"\n",
    "Label: na  \n",
    "Reason: No actual encounter or interaction.\n",
    "\n",
    "Sentence: \"We met some natives on the plain and continued on our way.\"\n",
    "Label: na  \n",
    "Reason: Too vague to assess sentiment or qualify as a meaningful interaction.\n",
    "\n",
    "Sentence: \"After giving them some bread and water, they smiled and sat with us by the fire.\"\n",
    "Label: positive  \n",
    "Reason: A warm, friendly interaction with emotional and physical closeness.\n",
    "\n",
    "Sentence: \"They ran off upon seeing us, and would not return even when we called.\"\n",
    "Label: negative  \n",
    "Reason: Suggests fear or distrust; emotionally charged avoidance.\n",
    "\n",
    "---\n",
    "\n",
    "Now, label the following sentences. Use this format:\n",
    "\n",
    "Sentence No.: <number>  \n",
    "Sentence: \"<exact sentence>\"  \n",
    "Label: <positive/negative/na>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83d99f63-f7c1-4236-ab06-8f0d155ce711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gpt_response(raw_text):\n",
    "    entries = []\n",
    "    pattern = re.compile(\n",
    "        r\"Sentence No\\.\\s*:\\s*(\\d+)\\s*\"\n",
    "        r\"Sentence\\s*:\\s*\\\"(.*?)\\\"\\s*\"\n",
    "        r\"Label\\s*:\\s*(positive|negative|na)\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    for match in pattern.finditer(raw_text):\n",
    "        sentence_no = int(match.group(1))\n",
    "        sentence = match.group(2).strip()\n",
    "        label = match.group(3).strip()\n",
    "        entries.append({\n",
    "            \"sentence_no\": sentence_no,\n",
    "            \"sentence\": sentence,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d83ff1-da0b-411a-ac98-4dad1ec93336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Resuming from checkpoint 4000\n",
      "üöÄ Run 0\n",
      "üèÅ Starting batch 4 at 2025-06-12 18:13:42.986123\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:24:55.377269, checkpoint saved: 5000, batch: 4\n",
      "üèÅ Starting batch 5 at 2025-06-12 18:38:38.363516\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:24:03.347503, checkpoint saved: 6000, batch: 5\n",
      "üèÅ Starting batch 6 at 2025-06-12 19:02:41.711197\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:30:25.422380, checkpoint saved: 7000, batch: 6\n",
      "üèÅ Starting batch 7 at 2025-06-12 19:33:07.133692\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:25:51.874535, checkpoint saved: 8000, batch: 7\n",
      "üèÅ Starting batch 8 at 2025-06-12 19:58:59.008372\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:28:08.198637, checkpoint saved: 9000, batch: 8\n",
      "üèÅ Starting batch 9 at 2025-06-12 20:27:07.207132\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:21:16.290134, checkpoint saved: 10000, batch: 9\n",
      "üèÅ Starting batch 10 at 2025-06-12 20:48:23.497417\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:23:33.672689, checkpoint saved: 11000, batch: 10\n",
      "üèÅ Starting batch 11 at 2025-06-12 21:11:57.170225\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:33:43.932585, checkpoint saved: 12000, batch: 11\n",
      "üèÅ Starting batch 12 at 2025-06-12 21:45:41.102956\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:25:54.746773, checkpoint saved: 13000, batch: 12\n",
      "üèÅ Starting batch 13 at 2025-06-12 22:11:35.849876\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n",
      "Finished batch 80\n",
      "Finished batch 81\n",
      "Finished batch 82\n",
      "Finished batch 83\n",
      "Finished batch 84\n",
      "Finished batch 85\n",
      "Finished batch 86\n",
      "Finished batch 87\n",
      "Finished batch 88\n",
      "Finished batch 89\n",
      "Finished batch 90\n",
      "Finished batch 91\n",
      "Finished batch 92\n",
      "Finished batch 93\n",
      "Finished batch 94\n",
      "Finished batch 95\n",
      "Finished batch 96\n",
      "Finished batch 97\n",
      "Finished batch 98\n",
      "Finished batch 99\n",
      "Finished batch 100\n",
      "‚úÖ Time: 0:23:39.125857, checkpoint saved: 14000, batch: 13\n",
      "üèÅ Starting batch 14 at 2025-06-12 22:35:14.975869\n",
      "Finished batch 1\n",
      "Finished batch 2\n",
      "Finished batch 3\n",
      "Finished batch 4\n",
      "Finished batch 5\n",
      "Finished batch 6\n",
      "Finished batch 7\n",
      "Finished batch 8\n",
      "Finished batch 9\n",
      "Finished batch 10\n",
      "Finished batch 11\n",
      "Finished batch 12\n",
      "Finished batch 13\n",
      "Finished batch 14\n",
      "Finished batch 15\n",
      "Finished batch 16\n",
      "Finished batch 17\n",
      "Finished batch 18\n",
      "Finished batch 19\n",
      "Finished batch 20\n",
      "Finished batch 21\n",
      "Finished batch 22\n",
      "Finished batch 23\n",
      "Finished batch 24\n",
      "Finished batch 25\n",
      "Finished batch 26\n",
      "Finished batch 27\n",
      "Finished batch 28\n",
      "Finished batch 29\n",
      "Finished batch 30\n",
      "Finished batch 31\n",
      "Finished batch 32\n",
      "Finished batch 33\n",
      "Finished batch 34\n",
      "Finished batch 35\n",
      "Finished batch 36\n",
      "Finished batch 37\n",
      "Finished batch 38\n",
      "Finished batch 39\n",
      "Finished batch 40\n",
      "Finished batch 41\n",
      "Finished batch 42\n",
      "Finished batch 43\n",
      "Finished batch 44\n",
      "Finished batch 45\n",
      "Finished batch 46\n",
      "Finished batch 47\n",
      "Finished batch 48\n",
      "Finished batch 49\n",
      "Finished batch 50\n",
      "Finished batch 51\n",
      "Finished batch 52\n",
      "Finished batch 53\n",
      "Finished batch 54\n",
      "Finished batch 55\n",
      "Finished batch 56\n",
      "Finished batch 57\n",
      "Finished batch 58\n",
      "Finished batch 59\n",
      "Finished batch 60\n",
      "Finished batch 61\n",
      "Finished batch 62\n",
      "Finished batch 63\n",
      "Finished batch 64\n",
      "Finished batch 65\n",
      "Finished batch 66\n",
      "Finished batch 67\n",
      "Finished batch 68\n",
      "Finished batch 69\n",
      "Finished batch 70\n",
      "Finished batch 71\n",
      "Finished batch 72\n",
      "Finished batch 73\n",
      "Finished batch 74\n",
      "Finished batch 75\n",
      "Finished batch 76\n",
      "Finished batch 77\n",
      "Finished batch 78\n",
      "Finished batch 79\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m label_runs \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_sentences_with_gpt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4.1-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå GPT labeling failed for batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mlabel_sentences_with_gpt\u001b[0;34m(sentences, model, batch_size, sleep_time)\u001b[0m\n\u001b[1;32m      7\u001b[0m instructions \u001b[38;5;241m=\u001b[39m [{\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeveloper\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: developer_prompt\n\u001b[1;32m      9\u001b[0m     },\n\u001b[1;32m     10\u001b[0m     {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentences:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mbatch_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     }]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     output  \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39moutput_text\n\u001b[1;32m     20\u001b[0m     labeled\u001b[38;5;241m.\u001b[39mappend((batch, output))\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/openai/resources/responses/responses.py:684\u001b[0m, in \u001b[0;36mResponses.create\u001b[0;34m(self, input, model, background, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    682\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    683\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response \u001b[38;5;241m|\u001b[39m Stream[ResponseStreamEvent]:\n\u001b[0;32m--> 684\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/responses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackground\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_output_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprevious_response_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/openai/_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/openai/_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    967\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    975\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "checkpoint = None\n",
    "\n",
    "try:\n",
    "    with open(\"checkpoint.txt\", 'r') as f:\n",
    "        checkpoint = int(f.read())\n",
    "        print(f\"üîÅ Resuming from checkpoint {checkpoint}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è No checkpoint found or error reading it: {e}\")\n",
    "    checkpoint = 0\n",
    "\n",
    "for run in range(1):  # Change to 5 for 5-run voting\n",
    "    print(f\"üöÄ Run {run}\")\n",
    "    \n",
    "    for start in range(checkpoint, len(sentences), batch_size):\n",
    "        now = datetime.datetime.now()\n",
    "        batch_num = start // batch_size\n",
    "        print(f\"üèÅ Starting batch {batch_num} at {now}\")\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        sentence_text_map = {}\n",
    "        label_runs = defaultdict(dict)\n",
    "\n",
    "        try:\n",
    "            results = label_sentences_with_gpt(\n",
    "                sentences[start: start+batch_size], \n",
    "                model=\"gpt-4.1-mini\", \n",
    "                batch_size=10, \n",
    "                sleep_time=2\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå GPT labeling failed for batch {batch_num}: {e}\")\n",
    "            continue\n",
    "                    \n",
    "        for _, output in results:\n",
    "            parsed = parse_gpt_response(output)\n",
    "            for row in parsed:\n",
    "                sn = row[\"sentence_no\"]\n",
    "                sentence_text_map[sn] = row[\"sentence\"]\n",
    "                label_runs[sn][f\"label_run_{run}\"] = row[\"label\"]\n",
    "    \n",
    "        rows = []\n",
    "        for sn, labels in label_runs.items():\n",
    "            row = {\"sentence_no\": sn, \"sentence\": sentence_text_map[sn]}\n",
    "            row.update(labels)\n",
    "            rows.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(rows).sort_values(by=\"sentence_no\").reset_index(drop=True)      \n",
    "        \n",
    "        output_dir = \"/cluster/home/hlee37/git/gutenberg/phase3/result\"\n",
    "        output_filename = f\"sentiment_annotation_gpt{batch_num}.csv\"\n",
    "        output_filepath = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        df.to_csv(output_filepath, index=False)\n",
    "        \n",
    "        # Save next start index\n",
    "        next_checkpoint = start + batch_size\n",
    "        with open(\"checkpoint.txt\", 'w') as f:\n",
    "            f.write(str(next_checkpoint))\n",
    "        \n",
    "        print(f\"‚úÖ Time: {datetime.datetime.now() - now}, checkpoint saved: {next_checkpoint}, batch: {batch_num}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242722d8-d292-4a25-9b8c-2de855159172",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0463937-3ab7-4f38-b122-75a948e5e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined DataFrame:\n",
      "   sentence_no                                           sentence label_run_0\n",
      "0            1  Here our dogs ran a native dog, but did not ki...    negative\n",
      "1            2  Wednesday, the25th August.-The two absentees d...          na\n",
      "2            3  Next morning, however, just when we were looki...          na\n",
      "3            4  They had continued down the creek without asce...          na\n",
      "4            5  They now returned and camped on Monday night a...          na\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/cluster/home/hlee37/git/gutenberg/phase3/result' # Replace with your actual folder path\n",
    "labled_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "all_dataframes = []\n",
    "for file in labled_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        all_dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"{e} exception at {file}\")\n",
    "        \n",
    "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "print(\"\\nCombined DataFrame:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a545872-22a5-45ef-8c07-9b2f10443067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_run_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>364</td>\n",
       "      <td>The two Somerset blacks evinced a great deal o...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353</th>\n",
       "      <td>365</td>\n",
       "      <td>Two of the black-boys were sent after them, an...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>367</td>\n",
       "      <td>In a late letter from Cape York, Mr. Frank Jar...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>369</td>\n",
       "      <td>From this is would appear that they closely wa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>370</td>\n",
       "      <td>The utter faithlessness, treachery, and savage...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13767</th>\n",
       "      <td>782</td>\n",
       "      <td>I should like much to send one or two of the C...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13768</th>\n",
       "      <td>783</td>\n",
       "      <td>I believe that the reports which they would br...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>784</td>\n",
       "      <td>Next, the determined hostility of the natives,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13770</th>\n",
       "      <td>785</td>\n",
       "      <td>They are on good terms with the natives, and t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13771</th>\n",
       "      <td>786</td>\n",
       "      <td>The natives of Cape York from the first have s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_no                                           sentence  \\\n",
       "5352           364  The two Somerset blacks evinced a great deal o...   \n",
       "5353           365  Two of the black-boys were sent after them, an...   \n",
       "5355           367  In a late letter from Cape York, Mr. Frank Jar...   \n",
       "5357           369  From this is would appear that they closely wa...   \n",
       "5358           370  The utter faithlessness, treachery, and savage...   \n",
       "...            ...                                                ...   \n",
       "13767          782  I should like much to send one or two of the C...   \n",
       "13768          783  I believe that the reports which they would br...   \n",
       "13769          784  Next, the determined hostility of the natives,...   \n",
       "13770          785  They are on good terms with the natives, and t...   \n",
       "13771          786  The natives of Cape York from the first have s...   \n",
       "\n",
       "      label_run_0  \n",
       "5352           na  \n",
       "5353           na  \n",
       "5355           na  \n",
       "5357     negative  \n",
       "5358     negative  \n",
       "...           ...  \n",
       "13767          na  \n",
       "13768    positive  \n",
       "13769    negative  \n",
       "13770    positive  \n",
       "13771    positive  \n",
       "\n",
       "[732 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[combined_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422175a7-6433-4ae9-8dc3-0f596d418560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13986, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25895ff6-beb1-4540-b79e-b6eff97ae64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = combined_df[~combined_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec9d2d0e-e551-4c43-b790-561ea1aca50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_run_0\n",
       "na          4449\n",
       "negative    5640\n",
       "positive    3165\n",
       "Name: sentence, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.groupby(['label_run_0'])['sentence'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa101c-85fd-4f0a-833e-cb7c01052589",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad561ac-94be-417c-abce-f152bd045e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c64fc0-bef7-4268-8e7a-8c40a49d01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['label_run_0'] != 'na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa56302-8fbc-4fd6-a981-62969773c0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_run_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Here our dogs ran a native dog, but did not kill him.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Next morning they had come on our returning tracks and had followed them to the camp; they had seen a great number of natives, and had spoken with some of them; they had seen the little gin with the white patch on the neck, who passed our camp in going up to the Bunya Bunya.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>We were encamped for a short time, and the fat cake not quite ready, when two natives walked boldly up after having cooeed and received our cooee in return.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>I gave each of them three brass buttons, to show our friendly intentions, and gave them to understand that we were to sleep one night and then continue to the westward.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>We parted good friends, thought Mr. Bunce told me that he heard them talking near our waterhole-they came perhaps there to fetch water.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13980</th>\n",
       "      <td>995</td>\n",
       "      <td>For a long time previous, the natives who visited the Settlement had been made to understand that Mr. Jardine expected his sons with horses and cattle, and had been familiarized with their names, \"Franco\" \"Alico\" as also with others such as \"Somerset,\" \"Cape York,\" \"Salamander,\" and \"Toby,\" (Mr. Jardine's well-known retreiver) the intention being that these should act as pass words when they met the party, a wise precaution, which, as it has been seen, probably prevented a collision.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13981</th>\n",
       "      <td>996</td>\n",
       "      <td>Thus, on nearing the Settlement the blacks set up the shouts that had alarmed him, screaming out his name Joko, Franco, Alicko, and such was the eagerness of each to prove that he (smiting himself on the breast) was \"Kotaiga\" or friend, pointing at the same time to the Brothers, as a witness of their truth, that it was with some difficulty that the Father could reach his sons to greet and welcome them.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13982</th>\n",
       "      <td>997</td>\n",
       "      <td>During the hubbub caused by the tumultuous demonstrativeness of the natives, an amusing episode occurred, which is worthy of record.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13983</th>\n",
       "      <td>998</td>\n",
       "      <td>The two Somerset blacks evinced a great deal of surprise at sight of the cattle, and expressed it by chirping and making various curious noises with their tongues and mouths.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13985</th>\n",
       "      <td>1000</td>\n",
       "      <td>Here they met the same tribe, (known as Wognie's,) and bartered \"bacca\" and \"bissika,\" against \"moro wappi,\" or fish, with which the camp was plentifully supplied in the evening.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8805 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_no  \\\n",
       "0                1   \n",
       "5                6   \n",
       "7                8   \n",
       "8                9   \n",
       "9               10   \n",
       "...            ...   \n",
       "13980          995   \n",
       "13981          996   \n",
       "13982          997   \n",
       "13983          998   \n",
       "13985         1000   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       sentence  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                         Here our dogs ran a native dog, but did not kill him.   \n",
       "5                                                                                                                                                                                                                           Next morning they had come on our returning tracks and had followed them to the camp; they had seen a great number of natives, and had spoken with some of them; they had seen the little gin with the white patch on the neck, who passed our camp in going up to the Bunya Bunya.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                  We were encamped for a short time, and the fat cake not quite ready, when two natives walked boldly up after having cooeed and received our cooee in return.   \n",
       "8                                                                                                                                                                                                                                                                                                                                      I gave each of them three brass buttons, to show our friendly intentions, and gave them to understand that we were to sleep one night and then continue to the westward.   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                       We parted good friends, thought Mr. Bunce told me that he heard them talking near our waterhole-they came perhaps there to fetch water.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...   \n",
       "13980  For a long time previous, the natives who visited the Settlement had been made to understand that Mr. Jardine expected his sons with horses and cattle, and had been familiarized with their names, \"Franco\" \"Alico\" as also with others such as \"Somerset,\" \"Cape York,\" \"Salamander,\" and \"Toby,\" (Mr. Jardine's well-known retreiver) the intention being that these should act as pass words when they met the party, a wise precaution, which, as it has been seen, probably prevented a collision.   \n",
       "13981                                                                                     Thus, on nearing the Settlement the blacks set up the shouts that had alarmed him, screaming out his name Joko, Franco, Alicko, and such was the eagerness of each to prove that he (smiting himself on the breast) was \"Kotaiga\" or friend, pointing at the same time to the Brothers, as a witness of their truth, that it was with some difficulty that the Father could reach his sons to greet and welcome them.   \n",
       "13982                                                                                                                                                                                                                                                                                                                                                                      During the hubbub caused by the tumultuous demonstrativeness of the natives, an amusing episode occurred, which is worthy of record.   \n",
       "13983                                                                                                                                                                                                                                                                                                                            The two Somerset blacks evinced a great deal of surprise at sight of the cattle, and expressed it by chirping and making various curious noises with their tongues and mouths.   \n",
       "13985                                                                                                                                                                                                                                                                                                                        Here they met the same tribe, (known as Wognie's,) and bartered \"bacca\" and \"bissika,\" against \"moro wappi,\" or fish, with which the camp was plentifully supplied in the evening.   \n",
       "\n",
       "      label_run_0  \n",
       "0        negative  \n",
       "5        positive  \n",
       "7        positive  \n",
       "8        positive  \n",
       "9        positive  \n",
       "...           ...  \n",
       "13980    positive  \n",
       "13981    positive  \n",
       "13982    positive  \n",
       "13983    positive  \n",
       "13985    positive  \n",
       "\n",
       "[8805 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2b4818-8a65-4d2e-948b-05765dc68061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8805, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c42e1b9-8a66-4c95-a363-aba8ee7f121b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['sentence'].str.len().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2bcfca4-1e64-441e-b60e-8e7dcb09d8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3561"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['sentence'].str.len() < 200].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7db8ba-cc6e-45a4-8a90-ccd24844efc9",
   "metadata": {},
   "source": [
    "# Train BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00391275-3242-4540-a087-3da501bf6850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, IntervalStrategy\n",
    "from datasets import Dataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b21bdc5c-21db-4e2c-b9de-4f3593365972",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[['sentence', 'label_run_0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e69742-f339-4a42-9ebf-d504d6b9e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns = ['sentence', 'label']\n",
    "df_final = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9ec9313-f7b5-4458-b419-c9c828350ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        negative\n",
       "5        positive\n",
       "7        positive\n",
       "8        positive\n",
       "9        positive\n",
       "           ...   \n",
       "13980    positive\n",
       "13981    positive\n",
       "13982    positive\n",
       "13983    positive\n",
       "13985    positive\n",
       "Name: label, Length: 8805, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "147d1cf2-6c77-4eec-a6f1-9eac1864301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_183160/2998654369.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['label'] = df_final.iloc[:,1:].applymap(lambda x:1 if x == 'positive' else 0)\n"
     ]
    }
   ],
   "source": [
    "df_final['label'] = df_final.iloc[:,1:].applymap(lambda x:1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a8a7909-e30d-4eb9-af4f-86e529ae798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {0: 5640, 1: 3165}\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Load and encode labels\n",
    "\n",
    "class_counts = df_final[\"label\"].value_counts().to_dict()\n",
    "print(\"Class distribution:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d571ce4-e72e-46c7-a7bf-16b6c23f34f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6163, Val size: 1321, Test size: 1321\n",
      "Train ys 2215, Val ys 475, Test ys 475\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: 3-way Split ‚Üí train (70%), val (15%), test (15%)\n",
    "df_train, df_temp = train_test_split(df_final, test_size=0.3, stratify=df_final[\"label\"], random_state=42)\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp[\"label\"], random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(df_train)}, Val size: {len(df_val)}, Test size: {len(df_test)}\")\n",
    "print(f\"Train ys {len(df_train[df_train['label'] == 1])}, Val ys {len(df_val[df_val['label'] == 1])}, Test ys {len(df_test[df_test['label'] == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0110d619-c905-4560-89b4-ccce67bd1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For submission, max_length is :198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6163/6163 [00:03<00:00, 1547.48 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1321/1321 [00:00<00:00, 1562.75 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1321/1321 [00:00<00:00, 1567.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Tokenization\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "true_max_length = max([len(s.split()) for s in df_train['sentence']]) \n",
    "\n",
    "if true_max_length > 512:\n",
    "    print(f\"max length exceed 512 at {true_max_length}\")\n",
    "    true_max_length = 512\n",
    "    \n",
    "print(f\"For submission, max_length is :{true_max_length}\")\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence\"], padding=\"max_length\", truncation=True, max_length=true_max_length)\n",
    "\n",
    "\n",
    "# Convert to HuggingFace datasets\n",
    "train_ds = Dataset.from_pandas(df_train)\n",
    "val_ds = Dataset.from_pandas(df_val)\n",
    "test_ds = Dataset.from_pandas(df_test)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# train_ds.set_format(type = 'torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
    "# val_ds.set_format(type = 'torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
    "# test_ds.set_format(type = 'torch', columns = ['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c47c2-7a37-4493-9152-24fbe00a8597",
   "metadata": {},
   "source": [
    "# Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e0df1b5-f0ed-4a8b-b554-577159107d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09c4400e-3788-4da7-a6ba-e3e9d195887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Training arguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",                 # Folder to save checkpoints and logs\n",
    "    num_train_epochs=4,                     # Number of full passes through the training set\n",
    "    per_device_train_batch_size=16,         # Batch size per GPU/CPU for training\n",
    "    per_device_eval_batch_size=64,          # Batch size per GPU/CPU for evaluation (can be larger)\n",
    "    eval_strategy=IntervalStrategy.EPOCH,            # Run evaluation after each training epoch\n",
    "    save_strategy=IntervalStrategy.EPOCH,                  # Save model checkpoint after each epoch\n",
    "    logging_dir=\"./logs\",                   # Directory for storing logs (TensorBoard, etc.)\n",
    "    logging_steps=10,                       # Log metrics every 10 steps (if logging_strategy=\"steps\")\n",
    "    load_best_model_at_end=True,            # Restore the best model (lowest eval loss) at the end\n",
    "    metric_for_best_model=\"precision\",      # Metric to monitor for choosing the best model\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=1,                     # Keep only the most recent checkpoint (saves disk space)\n",
    "    report_to = \"none\",\n",
    "    run_name = \"bert_relationship_classifier_run_book1&2&3_precision\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdc7b122-8fc2-486d-8770-1607bbfbce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)  # Assumes model outputs logits\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_macro': f1,\n",
    "        'eval_precision': precision,  # renamed key\n",
    "        'recall_macro': recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8579c4fc-3680-48e7-8c78-d9f7dbac520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f06b5568-fa45-4551-9245-488f1d1378a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1544' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1544/1544 02:55, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.100608</td>\n",
       "      <td>0.964079</td>\n",
       "      <td>0.967449</td>\n",
       "      <td>0.964710</td>\n",
       "      <td>0.965354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.115989</td>\n",
       "      <td>0.960683</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.963235</td>\n",
       "      <td>0.966018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.117563</td>\n",
       "      <td>0.963071</td>\n",
       "      <td>0.966692</td>\n",
       "      <td>0.963906</td>\n",
       "      <td>0.964763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.109303</td>\n",
       "      <td>0.961068</td>\n",
       "      <td>0.965178</td>\n",
       "      <td>0.962300</td>\n",
       "      <td>0.963581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1544, training_loss=0.07039759127625839, metrics={'train_runtime': 175.4966, 'train_samples_per_second': 140.47, 'train_steps_per_second': 8.798, 'total_flos': 2508340468502880.0, 'train_loss': 0.07039759127625839, 'epoch': 4.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c83ba3bd-2dae-4730-8be3-bd277601966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final Test Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_precision': 0.9673375503162738, 'eval_loss': 0.09861911088228226, 'eval_accuracy': 0.9689629068887207, 'eval_f1_macro': 0.9662267368808324, 'eval_recall_macro': 0.96515117581187, 'eval_runtime': 2.9255, 'eval_samples_per_second': 451.545, 'eval_steps_per_second': 7.178, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: Final Evaluation on Held-out Test Set\n",
    "print(\"‚úÖ Final Test Evaluation:\")\n",
    "eval_results = trainer.evaluate(eval_dataset=test_ds)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53bde84f-e0c1-4cf9-83ef-98427fff2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output = trainer.predict(test_ds)\n",
    "\n",
    "pred_logits = pred_output.predictions\n",
    "true_labels = pred_output.label_ids\n",
    "pred_probs = torch.softmax(torch.tensor(pred_logits), dim=1).numpy()\n",
    "pred_labels = pred_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8a0e673-94ec-4c84-b3ef-560ba53430b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.98      0.98       846\n",
      "    positive       0.96      0.95      0.96       475\n",
      "\n",
      "    accuracy                           0.97      1321\n",
      "   macro avg       0.97      0.97      0.97      1321\n",
      "weighted avg       0.97      0.97      0.97      1321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "print(classification_report(true_labels, pred_labels, target_names=[\"negative\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32d0b4de-a411-41ab-86e7-360eb8cf20db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92d7211a-ae37-43e6-882e-9232cfb245e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0m0lEQVR4nO3dd1QU198G8GfpHSw0EUWwVxRL7I2IsccCqFHEklgwRmJvaKKiMXaxF6wRrMGoGDX2FhUxKnZFbKBYAJG6e98//LFvNoCyuDCU53POHp27d2afHcp+uXNnRiaEECAiIiIqIrSkDkBERESkSSxuiIiIqEhhcUNERERFCosbIiIiKlJY3BAREVGRwuKGiIiIihQWN0RERFSksLghIiKiIoXFDRERERUpLG6INMTBwQEDBgyQOkax06pVK7Rq1UrqGJ80ffp0yGQyxMbGSh2lwJHJZJg+fbpGthUZGQmZTIbAwECNbI8KJxY3VCgEBgZCJpMpHzo6OrCzs8OAAQPw9OlTqeMVaImJifj5559Ru3ZtGBkZwdzcHM2bN8emTZtQWO6+EhERgenTpyMyMlLqKJnI5XJs2LABrVq1QsmSJaGvrw8HBwd4e3vj0qVLUsfTiG3btmHRokVSx1BREDNRwaEjdQAidfz000+oUKECkpOTcf78eQQGBuL06dO4fv06DAwMJM12+/ZtaGkVrL8XYmJi0LZtW9y8eROenp7w8fFBcnIydu3aBS8vLxw4cABbt26Ftra21FE/KiIiAjNmzECrVq3g4OCg8tyff/4pTSgASUlJ6N69O0JDQ9GiRQtMmjQJJUuWRGRkJIKDg7Fx40ZERUWhbNmykmXUhG3btuH69ev44Ycf8mT7SUlJ0NFR7+Mou0zly5dHUlISdHV1NZiQChsWN1SofPXVV6hfvz4AYPDgwShdujTmzp2LkJAQuLu7S5pNX18/318zOTkZenp62RZVXl5euHnzJvbs2YMuXboo27///nuMHTsWv/76K+rWrYvx48fnV2QAH0aTjI2NNbItPT09jWwnN8aOHYvQ0FAsXLgw04esn58fFi5cmK95hBBITk6GoaFhvr5ubigUCqSmpsLAwECjf5jIZDLJ/9ChAkAQFQIbNmwQAMTFixdV2v/44w8BQMyePVul/ebNm6JHjx6iRIkSQl9fX7i4uIjff/8903bfvHkjfvjhB1G+fHmhp6cn7OzsRL9+/cTLly+VfZKTk8W0adOEk5OT0NPTE2XLlhVjx44VycnJKtsqX7688PLyEkIIcfHiRQFABAYGZnrN0NBQAUDs27dP2fbkyRPh7e0trKyshJ6enqhevbpYt26dynrHjh0TAMRvv/0mJk+eLMqUKSNkMpl48+ZNlvvs3LlzAoAYOHBgls+npaWJSpUqiRIlSoj3798LIYR4+PChACDmzZsnFixYIMqVKycMDAxEixYtxLVr1zJtIyf7OeNrd/z4cTFs2DBhaWkpLCwshBBCREZGimHDhonKlSsLAwMDUbJkSdGzZ0/x8OHDTOv/93Hs2DEhhBAtW7YULVu2zLSfgoKCxMyZM4WdnZ3Q19cXbdq0EXfv3s30HpYtWyYqVKggDAwMRIMGDcTJkyczbTMrjx8/Fjo6OuLLL7/8aL8Mfn5+AoC4e/eu8PLyEubm5sLMzEwMGDBAJCYmqvRdv369aN26tbC0tBR6enqiWrVqYvny5Zm2Wb58edGxY0cRGhoqXFxchL6+vli4cKFa2xBCiAMHDogWLVoIExMTYWpqKurXry+2bt0qhPiwf/+778uXL69cN6c/HwDEiBEjxJYtW0T16tWFjo6O2LNnj/I5Pz8/Zd/4+HgxatQo5c+lpaWlcHV1FZcvX/5kpozv4Q0bNqi8/s2bN0WvXr1E6dKlhYGBgahcubKYNGnSx75kVIhx5IYKtYw5GCVKlFC23bhxA02bNoWdnR0mTJgAY2NjBAcHo1u3bti1axe+/vprAMC7d+/QvHlz3Lx5EwMHDkS9evUQGxuLkJAQPHnyBKVLl4ZCoUCXLl1w+vRpfPvtt6hWrRquXbuGhQsX4s6dO9i7d2+WuerXrw9HR0cEBwfDy8tL5bmgoCCUKFECbm5uAD4cOvriiy8gk8ng4+MDS0tLHDx4EIMGDUJ8fHymEYGff/4Zenp6GDNmDFJSUrIdudi3bx8AoH///lk+r6Ojgz59+mDGjBk4c+YMXF1dlc9t2rQJCQkJGDFiBJKTk7F48WK0adMG165dg7W1tVr7OcPw4cNhaWmJadOmITExEQBw8eJFnD17Fp6enihbtiwiIyOxYsUKtGrVChERETAyMkKLFi3w/fffY8mSJZg0aRKqVasGAMp/szNnzhxoaWlhzJgxiIuLwy+//IK+ffviwoULyj4rVqyAj48PmjdvjtGjRyMyMhLdunVDiRIlPnko6eDBg0hPT0e/fv0+2u+/3N3dUaFCBfj7+yMsLAxr166FlZUV5s6dq5KrRo0a6NKlC3R0dLBv3z4MHz4cCoUCI0aMUNne7du30bt3b3z33XcYMmQIqlSpotY2AgMDMXDgQNSoUQMTJ06EhYUFrly5gtDQUPTp0weTJ09GXFwcnjx5ohyJMjExAQC1fz7++usvBAcHw8fHB6VLl850iDHD0KFDsXPnTvj4+KB69ep49eoVTp8+jZs3b6JevXofzZSVf/75B82bN4euri6+/fZbODg44P79+9i3bx9mzZqVsy8cFS5SV1dEOZHx1/uRI0fEy5cvxePHj8XOnTuFpaWl0NfXF48fP1b2bdu2rahVq5bKX44KhUI0adJEVKpUSdk2bdo0AUDs3r070+spFAohhBCbN28WWlpa4tSpUyrPr1y5UgAQZ86cUbb9e+RGCCEmTpwodHV1xevXr5VtKSkpwsLCQmU0ZdCgQcLW1lbExsaqvIanp6cwNzdXjqpkjEg4Ojoq2z6mW7duAkC2IztCCLF7924BQCxZskQI8f9/9RoaGoonT54o+124cEEAEKNHj1a25XQ/Z3ztmjVrJtLT01VeP6v3kTHitGnTJmXbjh07VEZr/i27kZtq1aqJlJQUZfvixYsFAOUIVEpKiihVqpRo0KCBSEtLU/YLDAwUAD45cjN69GgBQFy5cuWj/TJkjNz8dyTt66+/FqVKlVJpy2q/uLm5CUdHR5W28uXLCwAiNDQ0U/+cbOPt27fC1NRUNGrUSCQlJan0zfgZEEKIjh07qozWZFDn5wOA0NLSEjdu3Mi0Hfxn5Mbc3FyMGDEiU79/yy5TViM3LVq0EKampuLRo0fZvkcqWgrW7EeiT3B1dYWlpSXs7e3Rs2dPGBsbIyQkRPlX9uvXr/HXX3/B3d0dCQkJiI2NRWxsLF69egU3NzfcvXtXeXbVrl27UKdOnUwjDMCH4/YAsGPHDlSrVg1Vq1ZVbis2NhZt2rQBABw7dizbrB4eHkhLS8Pu3buVbX/++Sfevn0LDw8PAB/mSOzatQudO3eGEELlNdzc3BAXF4ewsDCV7Xp5eeVoTkVCQgIAwNTUNNs+Gc/Fx8ertHfr1g12dnbK5YYNG6JRo0Y4cOAAAPX2c4YhQ4Zkmrj87/eRlpaGV69eoWLFirCwsMj0vtXl7e2tMqrVvHlzAMCDBw8AAJcuXcKrV68wZMgQlcmsffv2VRkJzE7GPvvY/s3K0KFDVZabN2+OV69eqXwN/r1f4uLiEBsbi5YtW+LBgweIi4tTWb9ChQrKUcB/y8k2Dh8+jISEBEyYMCHTPJWMn4GPUffno2XLlqhevfont2thYYELFy7g2bNnn+z7KS9fvsTJkycxcOBAlCtXTuW5nLxHKpx4WIoKlYCAAFSuXBlxcXFYv349Tp48qTKR9969exBCYOrUqZg6dWqW23jx4gXs7Oxw//599OjR46Ovd/fuXdy8eROWlpbZbis7derUQdWqVREUFIRBgwYB+HBIqnTp0spf/i9fvsTbt2+xevVqrF69OkevUaFChY9mzpDxoZuQkAALC4ss+2RXAFWqVClT38qVKyM4OBiAevv5Y7mTkpLg7++PDRs24OnTpyqnpv/3Q1xd//0gyyhY3rx5AwB49OgRAKBixYoq/XR0dLI9XPJvZmZmAP5/H2oiV8Y2z5w5Az8/P5w7dw7v379X6R8XFwdzc3PlcnbfDznZxv379wEANWvWVOs9ZFD35yOn37u//PILvLy8YG9vDxcXF3To0AH9+/eHo6Oj2hkzitncvkcqnFjcUKHSsGFD5dlS3bp1Q7NmzdCnTx/cvn0bJiYmUCgUAIAxY8Zk+dcskPnD7GMUCgVq1aqFBQsWZPm8vb39R9f38PDArFmzEBsbC1NTU4SEhKB3797KkYKMvN98802muTkZateurbKc0zNhqlWrhr179+Kff/5BixYtsuzzzz//AECO/pr+t9zs56xyjxw5Ehs2bMAPP/yAxo0bw9zcHDKZDJ6ensrXyK3sTm8XGrq2T9WqVQEA165dg7Ozc47X+1Su+/fvo23btqhatSoWLFgAe3t76Onp4cCBA1i4cGGm/ZLVflV3G7ml7s9HTr933d3d0bx5c+zZswd//vkn5s2bh7lz52L37t346quvPjs3FX0sbqjQ0tbWhr+/P1q3bo1ly5ZhwoQJyr/sdHV1VSbIZsXJyQnXr1//ZJ+rV6+ibdu2uRrC9vDwwIwZM7Br1y5YW1sjPj4enp6eyuctLS1hamoKuVz+ybzq6tSpE/z9/bFp06Ysixu5XI5t27ahRIkSaNq0qcpzd+/ezdT/zp07yhENdfbzx+zcuRNeXl6YP3++si05ORlv375V6ZcXhw/Kly8P4MMoVOvWrZXt6enpiIyMzFRU/tdXX30FbW1tbNmyRe1JxR+zb98+pKSkICQkRGWU52OHQHO7DScnJwDA9evXP1r0Z7f/P/fn42NsbW0xfPhwDB8+HC9evEC9evUwa9YsZXGT09fL+F791M86FS2cc0OFWqtWrdCwYUMsWrQIycnJsLKyQqtWrbBq1So8f/48U/+XL18q/9+jRw9cvXoVe/bsydQv469od3d3PH36FGvWrMnUJykpSXnWT3aqVauGWrVqISgoCEFBQbC1tVUpNLS1tdGjRw/s2rUry1++/86rriZNmsDV1RUbNmzAH3/8ken5yZMn486dOxg3blymv6j37t2rMmfm77//xoULF5QfLOrs54/R1tbONJKydOlSyOVylbaMa+L8t+j5HPXr10epUqWwZs0apKenK9u3bt2qPHT1Mfb29hgyZAj+/PNPLF26NNPzCoUC8+fPx5MnT9TKlTGy899DdBs2bND4Ntq1awdTU1P4+/sjOTlZ5bl/r2tsbJzlYcLP/fnIilwuz/RaVlZWKFOmDFJSUj6Z6b8sLS3RokULrF+/HlFRUSrPaWoUjwoejtxQoTd27Fj06tULgYGBGDp0KAICAtCsWTPUqlULQ4YMgaOjI2JiYnDu3Dk8efIEV69eVa63c+dO9OrVCwMHDoSLiwtev36NkJAQrFy5EnXq1EG/fv0QHByMoUOH4tixY2jatCnkcjlu3bqF4OBgHDp0SHmYLDseHh6YNm0aDAwMMGjQoEwX3JszZw6OHTuGRo0aYciQIahevTpev36NsLAwHDlyBK9fv871vtm0aRPatm2Lrl27ok+fPmjevDlSUlKwe/duHD9+HB4eHhg7dmym9SpWrIhmzZph2LBhSElJwaJFi1CqVCmMGzdO2Sen+/ljOnXqhM2bN8Pc3BzVq1fHuXPncOTIEZQqVUqln7OzM7S1tTF37lzExcVBX18fbdq0gZWVVa73jZ6eHqZPn46RI0eiTZs2cHd3R2RkJAIDA+Hk5JSjkYH58+fj/v37+P7777F792506tQJJUqUQFRUFHbs2IFbt26pjNTlRLt27aCnp4fOnTvju+++w7t377BmzRpYWVllWUh+zjbMzMywcOFCDB48GA0aNECfPn1QokQJXL16Fe/fv8fGjRsBAC4uLggKCoKvry8aNGgAExMTdO7cWSM/H/+VkJCAsmXLomfPnqhTpw5MTExw5MgRXLx4UWWEL7tMWVmyZAmaNWuGevXq4dtvv0WFChUQGRmJ/fv3Izw8XK18VEhIco4WkZqyu4ifEELI5XLh5OQknJyclKca379/X/Tv31/Y2NgIXV1dYWdnJzp16iR27typsu6rV6+Ej4+PsLOzU16AzMvLS+W07NTUVDF37lxRo0YNoa+vL0qUKCFcXFzEjBkzRFxcnLLff08Fz3D37l3lhcZOnz6d5fuLiYkRI0aMEPb29kJXV1fY2NiItm3bitWrVyv7ZJzivGPHDrX2XUJCgpg+fbqoUaOGMDQ0FKampqJp06YiMDAw06mw/76I3/z584W9vb3Q19cXzZs3F1evXs207Zzs54997d68eSO8vb1F6dKlhYmJiXBzcxO3bt3Kcl+uWbNGODo6Cm1t7RxdxO+/+ym7i7stWbJElC9fXujr64uGDRuKM2fOCBcXF9G+ffsc7F0h0tPTxdq1a0Xz5s2Fubm50NXVFeXLlxfe3t4qp4lnnAr+7wtE/nv//PvChSEhIaJ27drCwMBAODg4iLlz54r169dn6pdxEb+s5HQbGX2bNGkiDA0NhZmZmWjYsKH47bfflM+/e/dO9OnTR1hYWGS6iF9Ofz7wv4v4ZQX/OhU8JSVFjB07VtSpU0eYmpoKY2NjUadOnUwXIMwuU3Zf5+vXr4uvv/5aWFhYCAMDA1GlShUxderULPNQ4ScTguNyRPRBZGQkKlSogHnz5mHMmDFSx5GEQqGApaUlunfvnuXhFiIq+DjnhoiKreTk5EzzLjZt2oTXr1+jVatW0oQios/GOTdEVGydP38eo0ePRq9evVCqVCmEhYVh3bp1qFmzJnr16iV1PCLKJRY3RFRsOTg4wN7eHkuWLMHr169RsmRJ9O/fH3PmzJH0buNE9Hk454aIiIiKFM65ISIioiKFxQ0REREVKcVuzo1CocCzZ89gamrKO8ISEREVEkIIJCQkoEyZMpkuhvpfxa64efbs2SdvdkhEREQF0+PHj1G2bNmP9il2xY2pqSmADzvHzMxM4jRERESUE/Hx8bC3t1d+jn9MsStuMg5FmZmZsbghIiIqZHIypYQTiomIiKhIYXFDRERERQqLGyIiIipSWNwQERFRkcLihoiIiIoUFjdERERUpLC4ISIioiKFxQ0REREVKSxuiIiIqEhhcUNERERFiqTFzcmTJ9G5c2eUKVMGMpkMe/fu/eQ6x48fR7169aCvr4+KFSsiMDAwz3MSERFR4SFpcZOYmIg6deogICAgR/0fPnyIjh07onXr1ggPD8cPP/yAwYMH49ChQ3mclIiIiAoLSW+c+dVXX+Grr77Kcf+VK1eiQoUKmD9/PgCgWrVqOH36NBYuXAg3N7e8iklEREQA5AqB+KQ0JKamf7Sfno4WrEwN8ilVZoXqruDnzp2Dq6urSpubmxt++OGHbNdJSUlBSkqKcjk+Pj6v4hUa71LSceh6NN6nyaWOQkREBYQQAgnJ6YhLSkPc+7QP//7rEZ+UhoSUjxc1GeqVs8Du4U3zOHH2ClVxEx0dDWtra5U2a2trxMfHIykpCYaGhpnW8ff3x4wZM/IrYqGw5uQDLD56V+oYRERUSOnpaEH2r2X5+zgIIaBjbAEA0NWW9nylQlXc5MbEiRPh6+urXI6Pj4e9vb2EifKHXCFw+dEb3I6OR1jUW1yJeoPIV+8z9fuqpo0E6YiIqKCRyQATfR2YG+rCzEAX5ka6H/5v+OHfjIeZgS70dP6/eDl58iR69x6MatWq4dChQ9DW1pbwXXxQqIobGxsbxMTEqLTFxMTAzMwsy1EbANDX14e+vn5+xCswElPSMWJbGI7ffpltHx0tGVb3d0GbqtbZ9iEiIsqOQqGAv78/pk2bBoVCATMzM7x48QK2trZSRytcxU3jxo1x4MABlbbDhw+jcePGEiWS1rO3SXj3r+Of/zyJw7YLj3DtaRzS5AIA0KxiabiUL4G65SxQzdYM2lofBhINdLVhol+ovvxERFRAxMTEoF+/fjh8+DAAoH///ggICICJiYnEyT6Q9NPt3bt3uHfvnnL54cOHCA8PR8mSJVGuXDlMnDgRT58+xaZNmwAAQ4cOxbJlyzBu3DgMHDgQf/31F4KDg7F//36p3kKeeZ+ajj1XniIhOevJWweuPcc/T+KyXb+UsR7WDWgAZ3uLPEpIRETF0V9//YW+ffsiOjoaRkZGWL58Oby8vKSOpULS4ubSpUto3bq1cjljboyXlxcCAwPx/PlzREVFKZ+vUKEC9u/fj9GjR2Px4sUoW7Ys1q5dW+ROA09Ok2PDmUjMO3Q7R/1LGesBAMwMddGrflk0cSqNSlYmMObIDBERaVB6ejp8fHwQHR2NGjVqIDg4GNWrV5c6ViYyIYSQOkR+io+Ph7m5OeLi4mBmZiZ1nExWHL+PBYdvKw8rAUBPl7JZ9jXS08aQ5o6wL2mUX/GIiKiYu3r1KlauXIn58+fDyCj/Pn/U+fxmcVOAHLv9At4bLiqX9bS1sMCjDjrVLiNhKiIiKs7+/PNPPHr0CEOGDJE0hzqf3zxuUUA8e5sE36BwAMA3X5TD5A7Voa0lUzndjoiIKL+kp6fDz88P/v7+0NHRgYuLC+rVqyd1rBxhcVMApMkVGPnbFbx5n4aadmaY0rE6DHSlv04AEREVT0+ePEHv3r1x+vRpAMCgQYMK5Nya7LC4KQB+/fM2Lj96A1N9HQT0qcfChoiIJHPgwAH0798fr169gqmpKdauXQt3d3epY6mFxzwkdvRmDFadeAAA+KVnbZQvZSxxIiIiKq4mT56Mjh074tWrV6hXrx6uXLlS6AobgMWN5H4J/XC694AmDviqlvRXdSQiouKrZMmSAICRI0fi7NmzcHJykjhR7vCwlESEENh6IQq3YxIAZH+6NxERUV5KTEyEsfGHowa+vr5o1KgRmjVrJnGqz8ORG4kM3xqGKXuvA/hwd9VypXitGiIiyj+pqan44YcfUL9+fbx79w4AIJPJCn1hA3DkJt+dvRcLv5AbuPvinbLt4mRXmBnoSpiKiIiKkwcPHsDDwwOXLl0CAOzbtw+9e/eWOJXmcOQmn+2+8lSlsDk3sQ3MDVnYEBFR/ti1axfq1q2LS5cuoUSJEggJCSlShQ3A4ibfPX2TBADwqG+P8GlfwtbcUOJERERUHCQnJ8PHxwc9e/ZEfHw8mjRpgvDwcHTu3FnqaBrH4iaf3X3xYQJxn0blYGGkJ3EaIiIqLsaOHYuAgAAAwPjx43H8+HGUK1dO4lR5g8VNPnqdmIrYd6kAgIpWJhKnISKi4mTy5MmoWbMmDh48iDlz5kBXt+hOiWBxk4/u/O+077IlDGGsz7ncRESUd5KSkrBt2zblso2NDa5evYr27dtLmCp/8BM2H939X3FT2dpU4iRERFSU3bp1C+7u7rh27Rp0dHSUVxnW0ioeYxrF410WAPdfvkPojWgAQCVrHpIiIqK8sWnTJri4uODatWuwsrJSXnW4OOHITR5SKAR2hj1B0MXHuPzojbK9rr2FdKGIiKhISkxMxMiRI7FhwwYAQJs2bbBlyxbY2ha/W/uwuMkjL+KT0XbBCSQkpwMAtLVkaFXZEh4N7PFldWuJ0xERUVFy48YNuLu7IyIiAlpaWvDz88PkyZOhra0tdTRJsLjJI7uvPFUWNpam+tg/shmszAwkTkVEREXR/fv3ERERAVtbW2zbtg2tWrWSOpKkWNzkkUev3gMAzA118ecPLVDCmNe0ISIizRFCQCaTAQC6dOmCtWvXonPnzrCyspI4mfQ4oTiPXHv6FgDg370WCxsiItKoq1evolmzZnj8+LGybdCgQSxs/ofFTR5ITpPj1vMPp33XLmsucRoiIioqhBBYtWoVGjVqhLNnz+LHH3+UOlKBxMNSeeBWdALSFQIljfVgZ8F7RxER0eeLj4/Ht99+i6CgIABAx44dsXz5colTFUwcuckD/zx5C+DDqE3G8VAiIqLcCgsLg4uLC4KCgqCjo4N58+YhJCQEpUuXljpagcSRmzxw9XEcAKC2HQ9JERHR5zl27Bjat2+P1NRUlCtXDkFBQfjiiy+kjlWgsbjJAxmTiWuXtZA0BxERFX5ffPEFqlSpAkdHR6xfv75YXnFYXSxuNCwxJR33XrwDwMnERESUOzdu3EDVqlWhra0NQ0NDHDt2DCVLluRUhxzinBsNu/EsHgoB2JgZ8KJ9RESkFiEEFi5ciLp168Lf31/ZXqpUKRY2auDIjYb9ezIxERFRTr1+/RoDBgzAvn37AADXr19XuVAf5RxHbjTs6pP/TSZmcUNERDl09uxZODs7Y9++fdDT00NAQAB+++03Fja5xOJGw64pR24sJM1BREQFn0KhwC+//IIWLVrg8ePHqFixIs6fP4/hw4ezsPkMLG40KO59GiL/d08pjtwQEdGn3L9/H9OmTYNcLkfv3r0RFhaGunXrSh2r0OOcGw269vTDIalyJY1gYcT7SRER0cdVqlQJy5YtgxACgwcP5miNhrC40aCrnExMREQfoVAoMGfOHLi6uqJhw4YAgMGDB0ucqujhYSkNuvk8HgBQk1cmJiKi/4iJiUH79u0xefJkeHh4IDExUepIRRZHbjQoNV0BADAz0JU4CRERFSR//fUX+vbti+joaBgaGsLPzw/GxsZSxyqyOHJDRESUR+RyOaZPnw5XV1dER0ejRo0auHTpEgYMGCB1tCKNIzdERER5ID4+Hl27dsXx48cBAAMHDsTSpUthZGQkbbBigMUNERFRHjAxMYGxsTGMjY2xcuVKfPPNN1JHKjZY3BAREWlIeno60tLSYGhoCC0tLWzcuBGxsbGoUqWK1NGKFc65ISIi0oAnT56gTZs2GDp0qLKtVKlSLGwkwOKGiIjoMx04cADOzs44deoU9uzZg8jISKkjFWssboiIiHIpLS0N48aNQ8eOHfHq1SvUq1cPYWFhcHBwkDpascY5Nxr0Z0SM1BGIiCifREVFwdPTE+fOnQMAjBw5EvPmzYO+vr7EyYjFjYbce/FO+X9DPQ6IEREVZQqFAu3bt8fNmzdhbm6O9evXo3v37lLHov/hp7CGxCenKf//ZXUbCZMQEVFe09LSwuLFi/HFF1/gypUrLGwKGBY3GlaupBFM9DkgRkRU1Dx48ACHDx9WLn/55Zc4c+YMKlSoIGEqygqLGyIiok/YtWsX6tati549e+L+/fvKdi0tfowWRPyqEBERZSM5ORk+Pj7o2bMn4uPjUaNGDejq8ubIBR2LGyIioizcvXsXTZo0QUBAAABg3LhxOHHiBMqVKydxMvoUTg4hIiL6j+3bt+Pbb79FQkICSpUqhU2bNqFDhw5Sx6IcYnFDRET0HxcuXEBCQgKaN2+Obdu2oWzZslJHIjWwuCEiIgIghIBMJgMAzJ07FxUrVsR3330HHR1+VBY2nHNDRETF3pYtW9CxY0ekp6cDAPT09DBixAgWNoUUixsiIiq2EhMTMXDgQPTr1w8HDx7Ehg0bpI5EGsCSlIiIiqUbN27A3d0dERERkMlk8PPzw8CBA6WORRog+chNQEAAHBwcYGBggEaNGuHvv//+aP9FixahSpUqMDQ0hL29PUaPHo3k5OR8SktERIWdEAIbNmxAgwYNEBERARsbGxw9ehR+fn7Q1taWOh5pgKTFTVBQEHx9feHn54ewsDDUqVMHbm5uePHiRZb9t23bhgkTJsDPzw83b97EunXrEBQUhEmTJuVzciIiKqxmzJiBgQMHIikpCV9++SWuXr2K1q1bSx2LNEjS4mbBggUYMmQIvL29Ub16daxcuRJGRkZYv359lv3Pnj2Lpk2bok+fPnBwcEC7du3Qu3fvT472EBERZfDw8ICZmRlmzZqF0NBQWFlZSR2JNEyy4iY1NRWXL1+Gq6vr/4fR0oKrqyvOnTuX5TpNmjTB5cuXlcXMgwcPcODAgY9eWCklJQXx8fEqDyIiKj6EEAgPD1cuV6tWDQ8fPsSkSZN4b6giSrKvamxsLORyOaytrVXara2tER0dneU6ffr0wU8//YRmzZpBV1cXTk5OaNWq1UcPS/n7+8Pc3Fz5sLe31+j7ICKigis+Ph59+vSBi4sLTp06pWwvWbKkhKkorxWqkvX48eOYPXs2li9fjrCwMOzevRv79+/Hzz//nO06EydORFxcnPLx+PHjfExMRERSuXLlClxcXLB9+3bIZDLcvHlT6kiUTyQ7Fbx06dLQ1tZGTEyMSntMTAxsbGyyXGfq1Kno168fBg8eDACoVasWEhMT8e2332Ly5MlZDi/q6+tDX19f82+AiIgKJCEEli9fDl9fX6SmpqJcuXLYvn07GjduLHU0yieSjdzo6enBxcUFR48eVbYpFAocPXo022/A9+/fZypgMk7bE0LkXVgiIioU3r59i169esHHxwepqano0qULrly5wsKmmJH0In6+vr7w8vJC/fr10bBhQyxatAiJiYnw9vYGAPTv3x92dnbw9/cHAHTu3BkLFixA3bp10ahRI9y7dw9Tp05F586deW0CIiLC3r17sWvXLujq6uKXX37BqFGjlPeLouJD0uLGw8MDL1++xLRp0xAdHQ1nZ2eEhoYqJxlHRUWpjNRMmTIFMpkMU6ZMwdOnT2FpaYnOnTtj1qxZUr0FIiIqQLy8vPDPP/+gd+/eaNCggdRxSCIyUcyO58THx8Pc3BxxcXEwMzPT2HbDot6g+/KzKFfSCCfH8WJQRET54fXr15gyZYryzFgqutT5/Oa9pYiIqFA6d+4cPD09ERUVhbi4OGzdulXqSFRAFKpTwYmIiBQKBebNm4cWLVogKioKTk5O+PHHH6WORQUIR26IiKjQiI2NhZeXFw4cOADgw9zN1atXa3SaARV+LG6IiKhQCA8PR6dOnfD06VPo6+tjyZIlGDJkCM+GokxY3BARUaFQtmxZAECVKlUQHByM2rVrS5yICioWN0REVGDFx8crDzmVLl0ahw4dQvny5WFiYiJxMirIOKGYiIgKpGPHjqFKlSrYuHGjsq1GjRosbOiTWNwQEVGBIpfLMWPGDLi6uiI6OhoBAQFQKBRSx6JChMUNEREVGM+fP0e7du0wffp0KBQKeHt749ixY1neGJkoO5xzQ0REBcLhw4fxzTff4MWLFzA2NsaKFSvQr18/qWNRIcTihoiIJPfgwQN89dVXkMvlqFWrFoKDg1G1alWpY1EhxeKGiIgk5+joiPHjx+PVq1dYuHAhDA0NpY5EhRiLGyIiksTBgwdRpUoVODo6AgBmzpzJC/KRRnCGFhER5au0tDSMGzcOHTp0gKenJ1JTUwGAhQ1pDEduiIgo30RFRcHT0xPnzp0DADRs2BBCCIlTUVHD4oaIiPJFSEgIBgwYgDdv3sDc3Bzr1q1Djx49pI5FRRAPSxERUZ5KTU2Fr68vunbtijdv3qBBgwYICwtjYUN5hsUNERHlKSEETp48CQD44YcfcPr0aeUkYqK8wMNSRESUJ4QQkMlk0NfXR3BwMK5du4auXbtKHYuKARY3RESkUSkpKRgzZgwsLCzw888/A/hwHRuO1lB+YXFDREQac+/ePXh4eCAsLAxaWlrw8vJCxYoVpY5FxQzn3BARkUYEBwejXr16CAsLQ6lSpRASEsLChiTB4oaIiD5LUlIShg4dCg8PDyQkJKBZs2YIDw9Hx44dpY5GxRQPSxERUa4JIeDq6oqzZ89CJpNh4sSJmDFjBnR0+PFC0uF3HxER5ZpMJsOQIUNw9+5dbNmyBe3atZM6EhEPSxERkXrev3+PmzdvKpcHDBiA27dvs7ChAoPFDRER5VhERAQaNmyIdu3a4dWrV8r2EiVKSJiKSBWLGyIiypHAwEDUr18fN27cQHp6OiIjI6WORJQlFjdERPRR7969g5eXF7y9vZGUlARXV1eEh4fDxcVF6mhEWWJxQ0RE2bp27RoaNGiATZs2QUtLCzNnzsShQ4dgbW0tdTSibPFsKSIiytbcuXNx69YtlClTBr/99htatGghdSSiT2JxQ0RE2QoICIChoSFmz54NS0tLqeMQ5QgPSxERkdKVK1cwduxYCCEAAObm5lizZg0LGypUPmvkJjk5GQYGBprKQkREEhFCYMWKFRg9ejRSU1NRvXp1eHt7Sx2LKFfUHrlRKBT4+eefYWdnBxMTEzx48AAAMHXqVKxbt07jAYmIKG/FxcXB3d0dI0aMQGpqKjp37oyuXbtKHYso19QubmbOnInAwED88ssv0NPTU7bXrFkTa9eu1Wg4IiLKWxcvXkTdunWxc+dO6OrqYsGCBfj9999RsmRJqaMR5Zraxc2mTZuwevVq9O3bF9ra2sr2OnXq4NatWxoNR0REeWf9+vVo2rQpHj58CAcHB5w+fRqjR4+GTCaTOhrRZ1G7uHn69CkqVqyYqV2hUCAtLU0joYiIKO9VrFgRcrkc3bt3x5UrV9CwYUOpIxFphNoTiqtXr45Tp06hfPnyKu07d+5E3bp1NRaMiIg07+3bt7CwsAAAtGjRAhcuXICLiwtHa6hIUbu4mTZtGry8vPD06VMoFArs3r0bt2/fxqZNm/DHH3/kRUYiIvpMCoUCCxYswKxZs3Du3DlUrVoVAFC/fn2JkxFpntqHpbp27Yp9+/bhyJEjMDY2xrRp03Dz5k3s27cPX375ZV5kJCKizxAbG4suXbpg7NixePv2LTZv3ix1JKI8lavr3DRv3hyHDx/WdBYiItKw06dPo3fv3njy5An09fWxePFifPvtt1LHIspTao/cODo64tWrV5na3759C0dHR42EIiKiz6NQKODv749WrVrhyZMnqFy5Mi5cuIDvvvuO82uoyFO7uImMjIRcLs/UnpKSgqdPn2okFBERfZ7AwEBMmjQJcrkc33zzDS5fvow6depIHYsoX+T4sFRISIjy/4cOHYK5ublyWS6X4+jRo3BwcNBoOCIiyp3+/ftj+/bt8PT0hLe3N0drqFjJcXHTrVs3AIBMJoOXl5fKc7q6unBwcMD8+fM1Go6IiHJGLpdj3bp1GDBgAPT09KCjo4NDhw6xqKFiKcfFjUKhAABUqFABFy9eROnSpfMsFBER5Vx0dDT69u2Lv/76C7du3cKCBQsAgIUNFVtqny318OHDvMhBRES5cOTIEXzzzTeIiYmBkZERL6ZKhFyeCp6YmIgTJ04gKioKqampKs99//33GglGRETZS09Px4wZMzBr1iwIIVCrVi0EBwcrL85HVJypXdxcuXIFHTp0wPv375GYmIiSJUsiNjYWRkZGsLKyYnFDRJTHnj59ij59+uDkyZMAgCFDhmDx4sUwNDSUOBlRwaD2qeCjR49G586d8ebNGxgaGuL8+fN49OgRXFxc8Ouvv+ZFRiIi+pekpCRcuXIFJiYm2LZtG1avXs3Chuhf1B65CQ8Px6pVq6ClpQVtbW2kpKTA0dERv/zyC7y8vNC9e/e8yElEVKwJIZQThCtWrIjg4GA4OTmhUqVKEicjKnjUHrnR1dWFltaH1aysrBAVFQUAMDc3x+PHjzWbjoiI8PjxY7Rs2RJHjhxRtrVv356FDVE21B65qVu3Li5evIhKlSqhZcuWmDZtGmJjY7F582bUrFkzLzISERVb+/btw4ABA/D69WuMGDECERER0NbWljoWUYGm9sjN7NmzYWtrCwCYNWsWSpQogWHDhuHly5dYtWqVxgMSERVHqamp+PHHH9GlSxe8fv0a9evXx8GDB1nYEOWA2iM39evXV/7fysoKoaGhGg1ERFTcRUZGwsPDA3///TcAYNSoUZg7dy709fUlTkZUOKg9cpOdsLAwdOrUSe31AgIC4ODgAAMDAzRq1Ej5w5ydt2/fYsSIEbC1tYW+vj4qV66MAwcO5DY2EVGB8vjxY9StWxd///03LCwssGfPHixatIiFDZEa1CpuDh06hDFjxmDSpEl48OABAODWrVvo1q0bGjRooLxFQ04FBQXB19cXfn5+CAsLQ506deDm5oYXL15k2T81NRVffvklIiMjsXPnTty+fRtr1qyBnZ2dWq9LRFRQlS1bFp07d8YXX3yB8PBw5X39iCjncnxYat26dRgyZAhKliyJN2/eYO3atViwYAFGjhwJDw8PXL9+HdWqVVPrxRcsWIAhQ4bA29sbALBy5Urs378f69evx4QJEzL1X79+PV6/fo2zZ89CV1cXAHgnciIq9O7fvw8LCwuUKlUKMpkMK1euhK6urvL3HBGpJ8cjN4sXL8bcuXMRGxuL4OBgxMbGYvny5bh27RpWrlypdmGTmpqKy5cvw9XV9f/DaGnB1dUV586dy3KdkJAQNG7cGCNGjIC1tTVq1qyJ2bNnQy6XZ/s6KSkpiI+PV3kQERUUwcHBqFu3Lry9vSGEAAAYGRmxsCH6DDkubu7fv49evXoBALp37w4dHR3MmzcPZcuWzdULx8bGQi6Xw9raWqXd2toa0dHRWa7z4MED7Ny5E3K5HAcOHMDUqVMxf/58zJw5M9vX8ff3h7m5ufJhb2+fq7xERJqUnJyMYcOGwcPDAwkJCXj9+jX/+CLSkBwXN0lJSTAyMgIAyGQy6OvrK08Jzy8KhQJWVlZYvXo1XFxc4OHhgcmTJ2PlypXZrjNx4kTExcUpH7zQIBFJ7c6dO/jiiy+Uv7smTpyI48ePw9zcXOJkREWDWqeCr127FiYmJgA+3JE2MDAQpUuXVumT0xtnli5dGtra2oiJiVFpj4mJgY2NTZbr2NraQldXV+U6D9WqVUN0dDRSU1Ohp6eXaR19fX2eZUBEBcbWrVvx3XffITExEZaWlti8eTPc3NykjkVUpOS4uClXrhzWrFmjXLaxscHmzZtV+shkshwXN3p6enBxccHRo0eVZwMoFAocPXoUPj4+Wa7TtGlTbNu2DQqFQnkLiDt37sDW1jbLwoaIqCB5//49pkyZgsTERLRq1Qpbt25FmTJlpI5FVOTkuLiJjIzU+Iv7+vrCy8sL9evXR8OGDbFo0SIkJiYqz57q378/7Ozs4O/vDwAYNmwYli1bhlGjRmHkyJG4e/cuZs+eneOCiohISkZGRggKClLOGeTVhonyhtpXKNYkDw8PvHz5EtOmTUN0dDScnZ0RGhqqnGQcFRWlHKEBAHt7exw6dAijR49G7dq1YWdnh1GjRmH8+PFSvQUioo/auHEj5HI5Bg4cCABo2LAhGjZsKHEqoqJNJjLOPSwm4uPjYW5ujri4OJiZmWlsu2FRb9B9+VmUK2mEk+Naa2y7RFQ4vXv3DiNGjMCmTZugr6+Pf/75B5UrV5Y6FlGhpc7nt6QjN0RERdG1a9fg7u6OW7duQUtLC1OmTIGTk5PUsYiKDRY3REQaIoTAunXrMHLkSCQnJ6NMmTLYtm0bWrZsKXU0omKFxQ0RkQYIIeDl5aU8i7R9+/bYtGkTLC0tJU5GVPzk6q7g9+/fx5QpU9C7d2/lTS4PHjyIGzduaDQcEVFhIZPJUKlSJWhra2POnDnYv38/Cxsiiahd3Jw4cQK1atXChQsXsHv3brx79w4AcPXqVfj5+Wk8IBFRQSWEwJs3b5TLkyZNwuXLlzF+/HiVMz2JKH+p/dM3YcIEzJw5E4cPH1a5cF6bNm1w/vx5jYYjIiqo4uLi4OHhgVatWiEpKQkAoK2tjTp16kicjIjULm6uXbuGr7/+OlO7lZUVYmNjNRKKiKggu3TpEurVq4cdO3YgIiICZ86ckToSEf2L2sWNhYUFnj9/nqn9ypUrsLOz00goIqKCSAiBJUuWoEmTJnjw4AHKly+P06dPw9XVVepoRPQvahc3np6eGD9+PKKjoyGTyaBQKHDmzBmMGTMG/fv3z4uMRESSe/PmDbp3745Ro0YhLS0N3bp1w5UrV9CoUSOpoxHRf6hd3MyePRtVq1aFvb093r17h+rVq6NFixZo0qQJpkyZkhcZiYgkN3z4cOzduxd6enpYsmQJdu/ejRIlSkgdi4iyoPZ1bvT09LBmzRpMnToV169fx7t371C3bl1UqlQpL/IRERUIc+fOxf3797FixQq4uLhIHYeIPkLt4ub06dNo1qwZypUrh3LlyuVFJiIiyb169Qr79u3DgAEDAADlypXDhQsXIJPJpA1GRJ+k9mGpNm3aoEKFCpg0aRIiIiLyIhMRkaTOnDkDZ2dneHt7Y9++fcp2FjZEhYPaxc2zZ8/w448/4sSJE6hZsyacnZ0xb948PHnyJC/yERHlG4VCgTlz5qBly5Z48uQJKlWqBHt7e6ljEZGa1C5uSpcuDR8fH5w5cwb3799Hr169sHHjRjg4OKBNmzZ5kZGIKM+9ePECHTp0wMSJEyGXy9GnTx9cvnwZzs7OUkcjIjV91vXBK1SogAkTJmDOnDmoVasWTpw4oalcRET55sSJE3B2dsahQ4dgYGCAtWvXYsuWLTA1NZU6GhHlQq6LmzNnzmD48OGwtbVFnz59ULNmTezfv1+T2YiI8sXz58/x/PlzVKtWDRcvXsSgQYM4v4aoEFP7bKmJEydi+/btePbsGb788kssXrwYXbt2hZGRUV7kIyLKE0IIZQHj6emJ1NRU9OjRA8bGxhInI6LPpfbIzcmTJzF27Fg8ffoUf/zxB3r37s3ChogKlaNHj6JevXqIjo5WtvXv35+FDVERofbIDW8QR0SFlVwux4wZMzBz5kwIITBjxgysWLFC6lhEpGE5Km5CQkLw1VdfQVdXFyEhIR/t26VLF40EIyLSpGfPnqFPnz7KEx8GDx6M+fPnS5yKiPJCjoqbbt26ITo6GlZWVujWrVu2/WQyGeRyuaayERFpxKFDh/DNN98gNjYWJiYmWLVqFfr06SN1LCLKIzkqbhQKRZb/JyIq6Hbs2AF3d3cAQJ06dRAcHIzKlStLnIqI8pLaE4o3bdqElJSUTO2pqanYtGmTRkIREWlK+/btUblyZQwfPhznz59nYUNUDKhd3Hh7eyMuLi5Te0JCAry9vTUSiojoc5w/fx5CCACAqakpLl68iICAABgYGEicjIjyg9rFzb+vDfFvT548gbm5uUZCERHlRmpqKsaMGYPGjRtj0aJFynYzMzPpQhFRvsvxqeB169aFTCaDTCZD27ZtoaPz/6vK5XI8fPgQ7du3z5OQRESfEhkZCU9PT1y4cAEA8PTpU4kTEZFUclzcZJwlFR4eDjc3N5iYmCif09PTg4ODA3r06KHxgEREn7J37154e3vj7du3sLCwwIYNGz56ZicRFW05Lm78/PwAAA4ODvDw8OCxayKSXEpKCsaNG4clS5YAABo1aoTt27fDwcFB2mBEJCm159x4eXmxsCGiAiEiIgLLly8HAPz44484efIkCxsiytnITcmSJXHnzh2ULl0aJUqU+Ojdcl+/fq2xcEREH1O3bl0sXboUZcuWRadOnaSOQ0QFRI6Km4ULF8LU1FT5/48VN0REeSU5ORnjx4/HoEGDULt2bQDA0KFDJU5FRAVNjoobLy8v5f8HDBiQV1mIiLJ1584duLu74+rVq/jzzz9x7do1lbM2iYgyqD3nJiwsDNeuXVMu//777+jWrRsmTZqE1NRUjYYjIgKAbdu2wcXFBVevXoWlpSUWLVrEwoaIsqV2cfPdd9/hzp07AIAHDx7Aw8MDRkZG2LFjB8aNG6fxgERUfL1//x5DhgxB37598e7dO7Rs2VJ5OQoiouyoXdzcuXMHzs7OAD7ckK5ly5bYtm0bAgMDsWvXLk3nI6JiKjo6Go0aNcLatWshk8kwbdo0HDlyBGXKlJE6GhEVcGqP6wohlHcGP3LkiPIMBXt7e8TGxmo2HREVW5aWlrCysoK1tTW2bt2Ktm3bSh2JiAoJtYub+vXrY+bMmXB1dcWJEyewYsUKAMDDhw9hbW2t8YBEVHwkJiZCW1sbBgYG0NbWxtatWwEANjY2EicjosJE7cNSixYtQlhYGHx8fDB58mRUrFgRALBz5040adJE4wGJqHi4fv06GjRogNGjRyvbbGxsWNgQkdrUHrmpXbu2ytlSGebNmwdtbW2NhCKi4kMIgfXr18PHxwfJycmIi4vDzJkzUapUKamjEVEhletzKS9fvoybN28CAKpXr4569eppLBQRFQ8JCQkYNmyY8vCTm5sbNm/ezMKGiD6L2sXNixcv4OHhgRMnTsDCwgIA8PbtW7Ru3Rrbt2+HpaWlpjMSURF09epVuLu7486dO9DW1sbMmTMxbtw4aGmpfbSciEiF2r9FRo4ciXfv3uHGjRt4/fo1Xr9+jevXryM+Ph7ff/99XmQkoiImJSUFHTp0wJ07d1C2bFmcOHECEyZMYGFDRBqh9shNaGgojhw5gmrVqinbqlevjoCAALRr106j4YioaNLX18eKFSuwZs0aBAYG8jAUEWmU2sWNQqGArq5upnZdXV3l9W+IiP7r8uXLePPmDVxdXQEAXbp0QefOnXkjXiLSOLXHgNu0aYNRo0bh2bNnyranT59i9OjRvMgWEWUihMDSpUvRpEkTeHh44PHjx8rnWNgQUV5Qu7hZtmwZ4uPj4eDgACcnJzg5OaFChQqIj4/H0qVL8yIjERVSb968QY8ePfD9998jNTUVLVq0gImJidSxiKiIU/uwlL29PcLCwnD06FHlqeDVqlVTDjUTEQHAhQsX4OnpicjISOjp6eHXX3+Fj48PR2uIKM+pVdwEBQUhJCQEqampaNu2LUaOHJlXuYiokBJCYOHChRg/fjzS09Ph6OiI4OBguLi4SB2NiIqJHB+WWrFiBXr37o1Lly7h7t27GDFiBMaOHZuX2YioEJLJZLh16xbS09PRq1cvhIWFsbAhonyV4+Jm2bJl8PPzw+3btxEeHo6NGzdi+fLleZmNiAqRf58tuXjxYmzZsgVBQUEwNzeXMBURFUc5Lm4ePHgALy8v5XKfPn2Qnp6O58+f50kwIiocFAoF5s6di06dOikLHENDQ/Tt25fza4hIEjmec5OSkgJjY2PlspaWFvT09JCUlJQnwYio4Hv58iX69++P0NBQAMDvv/+Or7/+WuJURFTcqTWheOrUqTAyMlIup6amYtasWSrDzgsWLNBcOiIqsE6ePInevXvj2bNnMDAwwLJly9CtWzepYxER5by4adGiBW7fvq3S1qRJEzx48EC5zCFooqJPLpfD398ffn5+UCgUqFatGoKDg1GzZk2poxERAVCjuDl+/HgexiCiwmL48OFYvXo1AGDAgAFYtmyZyiFrIiKpFYhb8AYEBMDBwQEGBgZo1KgR/v777xytt337dshkMg6FE+WjYcOGoWTJkti4cSM2bNjAwoaIChzJi5ugoCD4+vrCz88PYWFhqFOnDtzc3PDixYuPrhcZGYkxY8agefPm+ZSUqHiSy+U4d+6cctnZ2RmPHj1C//79JUxFRJQ9yYubBQsWYMiQIfD29kb16tWxcuVKGBkZYf369dmuI5fL0bdvX8yYMQOOjo75mJaoeHn27Bnatm2Lli1b4uLFi8p23h+KiAoySYub1NRUXL58WeW+VFpaWnB1dVX5S/G/fvrpJ1hZWWHQoEH5EZOoWDp06BCcnZ1x4sQJ6Ovr49mzZ1JHIiLKEbVvnKlJsbGxkMvlsLa2Vmm3trbGrVu3slzn9OnTWLduHcLDw3P0GikpKUhJSVEux8fH5zovUXGQnp6OqVOnYs6cOQCAOnXqIDg4GJUrV5Y4GRFRzuRq5ObUqVP45ptv0LhxYzx9+hQAsHnzZpw+fVqj4f4rISEB/fr1w5o1a1C6dOkcrePv7w9zc3Plw97ePk8zEhVmjx8/RqtWrZSFzfDhw3H+/HkWNkRUqKhd3OzatQtubm4wNDTElStXlKMicXFxmD17tlrbKl26NLS1tRETE6PSHhMTAxsbm0z979+/j8jISHTu3Bk6OjrQ0dHBpk2bEBISAh0dHdy/fz/TOhMnTkRcXJzy8fjxY7UyEhUnu3fvxpkzZ2BmZobg4GAEBATAwMBA6lhERGpRu7iZOXMmVq5ciTVr1kBXV1fZ3rRpU4SFham1LT09Pbi4uODo0aPKNoVCgaNHj6Jx48aZ+letWhXXrl1DeHi48tGlSxe0bt0a4eHhWY7K6Ovrw8zMTOVBRFkbOXIkxo0bh7CwMPTq1UvqOEREuaL2nJvbt2+jRYsWmdrNzc3x9u1btQP4+vrCy8sL9evXR8OGDbFo0SIkJibC29sbANC/f3/Y2dnB398fBgYGma6CamFhAQC8OipRLjx69AhTp07F8uXLYWJiAi0tLcydO1fqWEREn0Xt4sbGxgb37t2Dg4ODSvvp06dzdVq2h4cHXr58iWnTpiE6OhrOzs4IDQ1VTjKOioqClpbkZ6wTFTm///47BgwYgLdv38LExATLly+XOhIRkUaoXdwMGTIEo0aNwvr16yGTyfDs2TOcO3cOY8aMwdSpU3MVwsfHBz4+Plk+96nbPgQGBubqNYmKq9TUVIwbNw6LFy8GADRs2BDjxo2TOBURkeaoXdxMmDABCoUCbdu2xfv379GiRQvo6+tjzJgxGDlyZF5kJCINefDgATw8PHDp0iUAwI8//ojZs2dDT09P4mRERJqjdnEjk8kwefJkjB07Fvfu3cO7d+9QvXp1XrGUqIA7fvw4unbtivj4eOW9oTp16iR1LCIijcv1Rfz09PRQvXp1TWYhojxUpUoVGBgYoFatWvjtt994zSciKrLULm5at24NmUyW7fN//fXXZwUiIs2JjY1VXvDS1tYWJ06cgJOTk8plHIiIihq1T0NydnZGnTp1lI/q1asjNTUVYWFhqFWrVl5kJKJc+O233+Do6IidO3cq26pWrcrChoiKPLVHbhYuXJhl+/Tp0/Hu3bvPDkREnycpKQmjRo3CmjVrAACbNm1Cz549JU5FRJR/NHYBmW+++Qbr16/X1OaIKBdu3bqFRo0aYc2aNZDJZJg6dSp2794tdSwionylsbuCnzt3jvegIZLQpk2bMGzYMLx//x7W1tbYsmULXF1dpY5FRJTv1C5uunfvrrIshMDz589x6dKlXF/Ej4g+T1hYGLy8vAAAbdq0wdatW7O8+SwRUXGgdnFjbm6usqylpYUqVargp59+Qrt27TQWjIhyrl69evjxxx9hbm6OSZMmQVtbW+pIRESSUau4kcvl8Pb2Rq1atVCiRIm8ykREnyCEwKZNm9C2bVuULVsWAPDrr79KnIqIqGBQa0KxtrY22rVrl6u7fxORZiQkJKBfv34YMGAAevfujfT0dKkjEREVKGqfLVWzZk08ePAgL7IQ0SdcvXoV9evXx9atW6GtrY2OHTtCS0tjJz0SERUJav9WnDlzJsaMGYM//vgDz58/R3x8vMqDiDRPCIFVq1ahUaNGuHPnDsqWLYsTJ05gwoQJLG6IiP4jx3NufvrpJ/z444/o0KEDAKBLly4qt2EQQkAmk0Eul2s+JVExlpCQgMGDByM4OBgA0KlTJwQGBqJUqVISJyMiKphyXNzMmDEDQ4cOxbFjx/IyDxH9h7a2NiIiIqCjo4M5c+bA19f3o/d3IyIq7nJc3AghAAAtW7bMszBE9IEQAkIIaGlpwcjICMHBwYiLi8MXX3whdTQiogJPrYP1/GuRKO+9ffsWPXv2xNy5c5Vt1apVY2FDRJRDal3npnLlyp8scF6/fv1ZgYiKs7///hseHh6IjIzEwYMHMXDgQFhbW0sdi4ioUFGruJkxY0amKxQT0ecTQmDRokUYP3480tLS4OjoiKCgIBY2RES5oFZx4+npCSsrq7zKQlQsvX79GgMGDMC+ffsAAD179sTatWv5hwQRUS7luLjhfBsizUtNTcUXX3yBu3fvQl9fHwsXLsTQoUP580ZE9BlyPKE442wpItIcPT09/PDDD6hUqRLOnz+PYcOGsbAhIvpMOS5uFAoFD0kRaUBsbCwiIiKUy8OGDUN4eDicnZ2lC0VEVITwuu1E+ejUqVOoU6cOOnfujLi4OAAfDvkaGRlJnIyIqOhgcUOUDxQKBWbNmoVWrVrh2bNn0NPTw8uXL6WORURUJKl1thQRqS8mJgb9+vXD4cOHAQBeXl4ICAiAsbGxxMmIiIomFjdEeeivv/5C3759ER0dDSMjIyxfvhxeXl5SxyIiKtJY3BDloYULFyI6Oho1atRAcHAwqlevLnUkIqIij3NuiPLQhg0bMGbMGPz9998sbIiI8gmLGyIN+vPPPzFmzBjlcunSpTFv3jyeDUVElI94WIpIA9LT0+Hn5wd/f38IIdCkSRN0795d6lhERMUSixuiz/TkyRP06dMHp06dAgAMHToUX331lcSpiIiKLxY3RJ/hwIED6N+/P169egVTU1OsXbsW7u7uUsciIirWOOeGKJdmz56Njh074tWrV3BxccGVK1dY2BARFQAsbohyycXFBTKZDCNHjsSZM2fg5OQkdSQiIgIPSxGp5cWLF8obyLq5ueHGjRuoVq2axKmIiOjfOHJDlAOpqakYPXo0qlSpggcPHijbWdgQERU8LG6IPuHhw4do1qwZFi1ahLdv3+LgwYNSRyIioo9gcUP0Ebt27ULdunVx8eJFlCxZEiEhIRgxYoTUsYiI6CNY3BBlITk5GT4+PujZsyfi4uLQpEkTXLlyBZ07d5Y6GhERfQKLG6IsLFmyBAEBAQCA8ePH4/jx4yhXrpzEqYiIKCd4thRRFkaNGoVjx47h+++/59WGiYgKGY7cEAFISkrCr7/+ivT0dACAvr4+Dh48yMKGiKgQ4sgNFXu3bt2Cu7s7rl27hrdv32LmzJlSRyIios/AkRsq1jZv3oz69evj2rVrsLa2RqtWraSOREREn4nFDRVLiYmJGDhwIPr374/ExES0adMG4eHhcHV1lToaERF9JhY3VOzcvHkTDRs2xIYNG6ClpYUZM2bgzz//hI2NjdTRiIhIAzjnhoodhUKBhw8fwtbWFtu2beOhKCKiIobFDRULcrkc2traAIAaNWpgz549qFu3rvImmEREVHTwsBQVeVevXkXt2rVx+vRpZZubmxsLGyKiIorFDRVZQgisWrUKjRo1QkREBMaOHQshhNSxiIgoj7G4oSIpPj4evXv3xtChQ5GSkoIOHTpg3759kMlkUkcjIqI8xuKGipywsDC4uLggKCgIOjo6mDdvHvbt24fSpUtLHY2IiPIBJxRTkXL9+nU0btwYqampKFeuHLZv347GjRtLHYuIiPIRixsqUmrUqIFOnTohPT0dGzZsQMmSJaWORERE+axAHJYKCAiAg4MDDAwM0KhRI/z999/Z9l2zZg2aN2+OEiVKoESJEnB1df1ofyr6Ll26hLi4OACATCbDli1bsHfvXhY2RETFlOTFTVBQEHx9feHn54ewsDDUqVMHbm5uePHiRZb9jx8/jt69e+PYsWM4d+4c7O3t0a5dOzx9+jSfk5PUhBBYuHAhmjRpgm+//VZ5JpShoSEnDhMRFWOSFzcLFizAkCFD4O3tjerVq2PlypUwMjLC+vXrs+y/detWDB8+HM7OzqhatSrWrl0LhUKBo0eP5nNyktLr16/RrVs3+Pr6Ii0tDQqFAqmpqVLHIiKiAkDS4iY1NRWXL19WuVmhlpYWXF1dce7cuRxt4/3790hLS+MhiGLk3LlzcHZ2RkhICPT09BAQEIDg4GDo6+tLHY2IiAoASScUx8bGQi6Xw9raWqXd2toat27dytE2xo8fjzJlymR7N+eUlBSkpKQol+Pj43MfmCSlUCjw66+/YtKkSZDL5ahYsSKCg4NRt25dqaMREVEBIvlhqc8xZ84cbN++HXv27IGBgUGWffz9/WFubq582Nvb53NK0pS3b99i8eLFkMvl6N27N8LCwljYEBFRJpIWN6VLl4a2tjZiYmJU2mNiYmBjY/PRdX/99VfMmTMHf/75J2rXrp1tv4kTJyIuLk75ePz4sUayU/4rWbIkfvvtN6xevRpbt26Fqamp1JGIiKgAkrS40dPTg4uLi8pk4IzJwR+78Novv/yCn3/+GaGhoahfv/5HX0NfXx9mZmYqDyocFAoFZs2ahS1btijbWrRogSFDhvBsKCIiypbkF/Hz9fWFl5cX6tevj4YNG2LRokVITEyEt7c3AKB///6ws7ODv78/AGDu3LmYNm0atm3bBgcHB0RHRwMATExMYGJiItn7IM2KiYlBv379cPjwYRgZGaF169aws7OTOhYRERUCkhc3Hh4eePnyJaZNm4bo6Gg4OzsjNDRUOck4KioKWlr/P8C0YsUKpKamomfPnirb8fPzw/Tp0/MzOuWRY8eOoU+fPoiOjoahoSGWLVuGMmXKSB2LiIgKCcmLGwDw8fGBj49Pls8dP35cZTkyMjLvA5Ek5HI5Zs6ciZ9++gkKhQI1atRAcHAwqlevLnU0IiIqRApEcUOUnp6O9u3bK+dfDRo0CEuWLIGRkZHEyYiIqLAp1KeCU9Gho6ODBg0awNjYGFu2bMHatWtZ2BARUa6wuCHJpKen4+XLl8rln376CVevXkXfvn0lTEVERIUdixuSxJMnT9C6dWt07NhReU8oXV1dODk5SZyMiIgKOxY3lO8OHDgAZ2dnnD59Grdu3cL169eljkREREUIixvKN2lpaRg3bhw6duyIV69eoV69eggLC0O9evWkjkZEREUIz5aifPHo0SN4enri/PnzAICRI0di3rx5vJM3ERFpHIsbyheDBw/G+fPnYW5ujvXr16N79+5SRyIioiKKh6UoX6xYsQKurq64cuUKCxsiIspTLG4oTzx8+BBr165VLlesWBGHDx9GhQoVJExFRETFAQ9Lkcbt2rULgwYNQnx8PBwcHODq6ip1JCIiKkY4ckMak5ycDB8fH/Ts2RNxcXH44osvUKlSJaljERFRMcPihjTi3r17aNKkCQICAgAA48aNw4kTJ1C+fHmJkxERUXHDw1L02Xbs2IFBgwYhISEBpUqVwqZNm9ChQwepYxERUTHF4oY+27t375CQkIDmzZtj27ZtKFu2rNSRiIioGGNxQ7mSnp4OHZ0P3z4DBgyAiYkJvv76a2UbERGRVDjnhtS2efNm1K5dG69evQIAyGQy9OrVi4UNEREVCCxuKMcSExMxcOBA9O/fHzdv3sSSJUukjkRERJQJ/9SmHLlx4wbc3d0REREBmUwGPz8/TJkyRepYREREmbC4oY8SQiAwMBAjRoxAUlISbGxssG3bNrRu3VrqaERERFniYSn6qOXLl2PgwIFISkrCl19+ifDwcBY2RERUoLG4oY/q27cvKlasiFmzZiE0NBTW1tZSRyIiIvooHpYiFUIIHDlyBK6urpDJZLCwsMC1a9dgYGAgdTQiIqIc4cgNKcXHx6NPnz5o164d1qxZo2xnYUNERIUJR24IAHDlyhW4u7vj3r170NHRQVJSktSRiIiIcoXFTTEnhMDy5cvh6+uL1NRUlCtXDtu3b0fjxo2ljkZERJQrLG6Ksbdv32Lw4MHYtWsXAKBLly7YsGEDSpYsKXEyIiKi3OOcm2Ls2rVr2LNnD3R1dbFw4ULs3buXhQ0RERV6HLkpxpo3b45ly5ahfv36aNCggdRxiIiINIIjN8XI69ev0adPH9y+fVvZNmzYMBY2RERUpHDkppg4d+4cPD09ERUVhXv37uHChQuQyWRSxyIiItI4jtwUcQqFAvPmzUOLFi0QFRUFJycnrFy5koUNEREVWRy5KcJiY2Ph5eWFAwcOAAA8PDywevVqmJmZSZyMiIgo77C4KaLu3buHVq1a4enTpzAwMMDixYsxZMgQjtgQEVGRx+KmiCpfvjzKly8PExMTBAcHo3bt2lJHIiIiyhcsboqQly9fwtzcHHp6etDV1cXOnTthamoKExMTqaMRERHlG04oLiKOHTuG2rVrY9KkSco2W1tbFjZERFTssLgp5ORyOWbMmAFXV1dER0cjNDQU79+/lzoWERGRZFjcFGLPnz9Hu3btMH36dCgUCgwcOBB///03jIyMpI5GREQkGc65KaQOHz6Mb775Bi9evICxsTFWrFiBfv36SR2LiIhIcixuCqG3b9+iV69eiIuLQ61atRAcHIyqVatKHYuIiKhAYHFTCFlYWGDlypU4duwYFi1aBENDQ6kjERERFRgsbgqJgwcPwsDAAK1btwYAeHp6wtPTU+JUREREBQ8nFBdwaWlpGD9+PDp06IDevXsjJiZG6khEREQFGkduCrCoqCh4enri3LlzAICePXvC3Nxc4lREREQFG4ubAiokJAQDBgzAmzdvYG5ujnXr1qFHjx5SxyIq1oQQSE9Ph1wulzoKUZGkq6sLbW3tz94Oi5sCRi6XY+zYsVi4cCEAoEGDBti+fTscHR0lTkZUvKWmpuL58+e8SCZRHpLJZChbtuxnX12fxU0Bo6WlhRcvXgAAfvjhB8ydOxd6enoSpyIq3hQKBR4+fAhtbW2UKVMGenp6kMlkUsciKlKEEHj58iWePHmCSpUqfdYIDoubAiI9PR06OjqQyWRYsWIF+vbti6+++krqWESED6M2CoUC9vb2vAI4UR6ytLREZGQk0tLSPqu44dlSEktJScHIkSPRo0cPCCEAAKampixsiAogLS3+yiTKS5oaEeXIjYTu3bsHDw8PhIWFAQBOnz6N5s2bS5yKiIiocOOfIRIJCgpCvXr1EBYWhlKlSuGPP/5gYUNERKQBLG7yWVJSEoYOHQpPT08kJCSgWbNmCA8PR8eOHaWORkRE/3P79m3Y2NggISFB6ihFhqenJ+bPn58vr8XiJp95enpi1apVkMlkmDRpEo4dO4ayZctKHYuIiqABAwZAJpNBJpNBV1cXFSpUwLhx45CcnJyp7x9//IGWLVvC1NQURkZGaNCgAQIDA7Pc7q5du9CqVSuYm5vDxMQEtWvXxk8//YTXr1/n8TvKPxMnTsTIkSNhamqa6bmqVatCX18f0dHRmZ5zcHDAokWLMrVPnz4dzs7OKm3R0dEYOXIkHB0doa+vD3t7e3Tu3BlHjx7V1NvI0o4dO1C1alUYGBigVq1aOHDgwCfXCQgIQLVq1WBoaIgqVapg06ZNKs+npaXhp59+gpOTEwwMDFCnTh2Ehoaq9JkyZQpmzZqFuLg4jb6frLC4yWeTJk2CnZ0dQkNDMWvWLOjocNoTEeWd9u3b4/nz53jw4AEWLlyIVatWwc/PT6XP0qVL0bVrVzRt2hQXLlzAP//8A09PTwwdOhRjxoxR6Tt58mR4eHigQYMGOHjwIK5fv4758+fj6tWr2Lx5c769r9TU1DzbdlRUFP744w8MGDAg03OnT59GUlISevbsiY0bN+b6NSIjI+Hi4oK//voL8+bNw7Vr1xAaGorWrVtjxIgRn5H+486ePYvevXtj0KBBuHLlCrp164Zu3brh+vXr2a6zYsUKTJw4EdOnT8eNGzcwY8YMjBgxAvv27VP2mTJlClatWoWlS5ciIiICQ4cOxddff40rV64o+9SsWRNOTk7YsmVLnr0/JVHMxMXFCQAiLi5Oo9u9/Oi1KD/+D9F87l8q7YmJieL48eMqbcnJyRp9bSLKW0lJSSIiIkIkJSUp2xQKhUhMScv3h0KhyHFuLy8v0bVrV5W27t27i7p16yqXo6KihK6urvD19c20/pIlSwQAcf78eSGEEBcuXBAAxKJFi7J8vTdv3mSb5fHjx8LT01OUKFFCGBkZCRcXF+V2s8o5atQo0bJlS+Vyy5YtxYgRI8SoUaNEqVKlRKtWrUTv3r2Fu7u7ynqpqamiVKlSYuPGjUIIIeRyuZg9e7ZwcHAQBgYGonbt2mLHjh3Z5hRCiHnz5on69etn+dyAAQPEhAkTxMGDB0XlypUzPV++fHmxcOHCTO1+fn6iTp06yuWvvvpK2NnZiXfv3mXq+7H9+Lnc3d1Fx44dVdoaNWokvvvuu2zXady4sRgzZoxKm6+vr2jatKly2dbWVixbtkylT/fu3UXfvn1V2mbMmCGaNWuW7Wtl9bOWQZ3Pbw4b5KGIiAi4u7vj/v37uHDhAmrXrg0A0NfXlzgZEX2upDQ5qk87lO+vG/GTG4z0cver+/r16zh79izKly+vbNu5cyfS0tIyjdAAwHfffYdJkybht99+Q6NGjbB161aYmJhg+PDhWW7fwsIiy/Z3796hZcuWsLOzQ0hICGxsbBAWFgaFQqFW/o0bN2LYsGE4c+YMgA9nnPbq1Qvv3r1TXtH20KFDeP/+Pb7++msAgL+/P7Zs2YKVK1eiUqVKOHnyJL755htYWlqiZcuWWb7OqVOnUL9+/UztCQkJ2LFjBy5cuICqVasiLi4Op06dUvtkkNevXytH742NjTM9n91+BICtW7fiu+++++j2Dx48mG2mc+fOwdfXV6XNzc0Ne/fuzXZ7KSkpMDAwUGkzNDTE33//jbS0NOjq6mbb5/Tp0yptDRs2xKxZs5CSkpKnn4UForgJCAjAvHnzEB0djTp16mDp0qVo2LBhtv137NiBqVOnIjIyEpUqVcLcuXPRoUOHfEz8cUIIBAYGYsSIEUhKSoKNjQ3i4+OljkVExdAff/wBExMTpKenIyUlBVpaWli2bJny+Tt37sDc3By2traZ1tXT04OjoyPu3LkDALh79y4cHR2hq6urVoZt27bh5cuXuHjxIkqWLAkAqFixotrvpVKlSvjll1+Uy05OTjA2NsaePXvQr18/5Wt16dIFpqamSElJwezZs3HkyBE0btwYAODo6IjTp09j1apV2RY3jx49yrK42b59OypVqoQaNWoA+DCHct26dWoXN/fu3YMQAlWrVlVrPQDo0qULGjVq9NE+dnZ22T4XHR0Na2trlTZra+ss5w9lcHNzw9q1a9GtWzfUq1cPly9fxtq1a5GWlobY2FjY2trCzc0NCxYsQIsWLeDk5ISjR49i9+7dme7DVqZMGaSmpiI6OlqlyNY0yYuboKAg+Pr6YuXKlWjUqBEWLVoENzc33L59G1ZWVpn6Zxwv9Pf3R6dOnbBt2zZ069YNYWFhqFmzpgTvQJU8JQleXl7KY89ffvklNm/enOmbiYgKN0NdbUT85CbJ66qjdevWWLFiBRITE7Fw4ULo6Ojk+ia84n8XGlVXeHg46tatqyxscsvFxUVlWUdHB+7u7ti6dSv69euHxMRE/P7779i+fTuAD0XE+/fv8eWXX6qsl5qairp162b7OklJSZlGIQBg/fr1+Oabb5TL33zzDVq2bImlS5dmOfE4O7ndj8CHi7yq81qaMHXqVERHR+OLL76AEALW1tbw8vLCL7/8oryw5eLFizFkyBBUrVoVMpkMTk5O8Pb2xvr161W2ZWhoCAB5fo82yScUL1iwAEOGDIG3tzeqV6+OlStXwsjIKNMOybB48WK0b98eY8eORbVq1fDzzz+jXr16Kn+JSCX1xUNcWToMmzdvhpaWFmbOnInQ0FAWNkRFkEwmg5GeTr4/1L2Cq7GxMSpWrIg6depg/fr1uHDhAtatW6d8vnLlyoiLi8OzZ88yrZuamor79++jcuXKyr4PHjxAWlqaWhkyPtCyo6WllekDP6vXyOoQTt++fXH06FG8ePECe/fuhaGhIdq3bw/gw+EwANi/fz/Cw8OVj4iICOzcuTPbPKVLl8abN29U2iIiInD+/HmMGzcOOjo60NHRwRdffIH3798riykAMDMzy/JsoLdv38Lc3BzAhxEomUyGW7duZZshOxmHBj/2OHXqVLbr29jYICYmRqUtJiYGNjY22a5jaGiI9evX4/3794iMjERUVBQcHBxgamoKS0tLAB9um7B3714kJibi0aNHuHXrFkxMTDLd9DnjjLqM9fKKpMVNamoqLl++DFdXV2WblpYWXF1dce7cuSzXOXfunEp/4MOQWXb9U1JSEB8fr/LIK+/vnkfSyyiUKVMGx44dw+TJk3m5diIqMLS0tDBp0iRMmTIFSUlJAIAePXpAV1c3y+uPrFy5EomJiejduzcAoE+fPnj37h2WL1+e5fbfvn2bZXvt2rURHh6e7anilpaWeP78uUpbeHh4jt5TkyZNYG9vj6CgIGzduhW9evVSHjarXr069PX1ERUVhYoVK6o87O3ts91m3bp1ERERodK2bt06tGjRAlevXlUplHx9fVWKxSpVquDy5cuZthkWFqYsEkuWLAk3NzcEBAQgMTExU9/s9iPw4bDUv18/q0dWh9QyNG7cONOp5ocPH1YetvsYXV1dlC1bFtra2ti+fTs6deqU6TPOwMAAdnZ2SE9Px65du9C1a1eV569fv46yZcuidOnSn3y9z/LJKcd56OnTpwKAOHv2rEr72LFjRcOGDbNcR1dXV2zbtk2lLSAgQFhZWWXZ38/PTwDI9ND02VJhj16LShP3CQfXfuLFixca3TYRSetjZ3AUZFmdhZSWlibs7OzEvHnzlG0LFy4UWlpaYtKkSeLmzZvi3r17Yv78+UJfX1/8+OOPKuuPGzdOaGtri7Fjx4qzZ8+KyMhIceTIEdGzZ89sz6JKSUkRlStXFs2bNxenT58W9+/fFzt37lT+7g8NDRUymUxs3LhR3LlzR0ybNk2YmZllOltq1KhRWW5/8uTJonr16kJHR0ecOnUq03OlSpUSgYGB4t69e+Ly5ctiyZIlIjAwMNv9FhISIqysrER6eroQ4sMZWJaWlmLFihWZ+kZERAgA4vr160IIIc6cOSO0tLTEzJkzRUREhLh27ZqYNGmS0NHREdeuXVOud//+fWFjYyOqV68udu7cKe7cuSMiIiLE4sWLRdWqVbPN9rnOnDkjdHR0xK+//ipu3rwp/Pz8hK6urkq2CRMmiH79+imXb9++LTZv3izu3LkjLly4IDw8PETJkiXFw4cPlX3Onz8vdu3aJe7fvy9Onjwp2rRpIypUqJDpzC8vLy8xcODAbPNp6mypIl/cJCcni7i4OOXj8ePHeVLcEFHRVZSKGyGE8Pf3F5aWliqnIf/++++iefPmwtjYWBgYGAgXFxexfv36LLcbFBQkWrRoIUxNTYWxsbGoXbu2+Omnnz56CnNkZKTo0aOHMDMzE0ZGRqJ+/friwoULyuenTZsmrK2thbm5uRg9erTw8fHJcXGTUWCUL18+06nyCoVCLFq0SFSpUkXo6uoKS0tL4ebmJk6cOJFt1rS0NFGmTBkRGhoqhBBi586dQktLS0RHR2fZv1q1amL06NHK5UOHDommTZuKEiVKKE9bz+r1nj17JkaMGCHKly8v9PT0hJ2dnejSpYs4duxYttk0ITg4WFSuXFno6emJGjVqiP3796s87+XlpbLvIyIihLOzszA0NBRmZmaia9eu4tatWyrrHD9+XFSrVk3o6+uLUqVKiX79+omnT5+q9ElKShLm5ubi3Llz2WbTVHEjE+IzZjZ9ptTUVBgZGWHnzp3o1q2bst3Lywtv377F77//nmmdcuXKwdfXFz/88IOyzc/PD3v37sXVq1c/+Zrx8fEwNzdHXFwczMzMNPE2iKiIS05OxsOHD1GhQoUsJ5pS0RMQEICQkBAcOpT/p/sXVStWrMCePXvw559/ZtvnYz9r6nx+SzohRE9PDy4uLirH/xQKBY4ePZrt8b/POV5IRESUE9999x1atGjBe0tpkK6uLpYuXZovryX5qeC+vr7w8vJC/fr10bBhQyxatAiJiYnw9vYGAPTv3x92dnbw9/cHAIwaNQotW7bE/Pnz0bFjR2zfvh2XLl3C6tWrpXwbRERUhOjo6GDy5MlSxyhSBg8enG+vJXlx4+HhgZcvX2LatGmIjo6Gs7OzyunTUVFRKrOxmzRpgm3btmHKlCmYNGkSKlWqhL179xaIa9wQERGR9CSdcyMFzrkhInVxzg1R/igSc26IiAqTYva3IFG+09TPGIsbIqJPyLgoXF5fMp6ouEtNTQUAaGurd5uR/5J8zg0RUUGnra0NCwsLvHjxAgBgZGSk9m0QiOjjFAoFXr58CSMjI+jofF55wuKGiCgHMu69k1HgEJHmaWlpoVy5cp/9xwOLGyKiHJDJZLC1tYWVlZXaN44kopzR09PTyD0ZWdwQEalBW1v7s+cDEFHe4oRiIiIiKlJY3BAREVGRwuKGiIiIipRiN+cm4wJB8fHxEichIiKinMr43M7Jhf6KXXGTcYdXe3t7iZMQERGRuhISEmBubv7RPsXu3lIKhQLPnj2Dqampxi/CFR8fD3t7ezx+/Jj3rcpD3M/5g/s5f3A/5x/u6/yRV/tZCIGEhASUKVPmk6eLF7uRGy0tLZQtWzZPX8PMzIw/OPmA+zl/cD/nD+7n/MN9nT/yYj9/asQmAycUExERUZHC4oaIiIiKFBY3GqSvrw8/Pz/o6+tLHaVI437OH9zP+YP7Of9wX+ePgrCfi92EYiIiIiraOHJDRERERQqLGyIiIipSWNwQERFRkcLihoiIiIoUFjdqCggIgIODAwwMDNCoUSP8/fffH+2/Y8cOVK1aFQYGBqhVqxYOHDiQT0kLN3X285o1a9C8eXOUKFECJUqUgKur6ye/LvSBut/PGbZv3w6ZTIZu3brlbcAiQt39/PbtW4wYMQK2trbQ19dH5cqV+bsjB9Tdz4sWLUKVKlVgaGgIe3t7jB49GsnJyfmUtnA6efIkOnfujDJlykAmk2Hv3r2fXOf48eOoV68e9PX1UbFiRQQGBuZ5TgjKse3btws9PT2xfv16cePGDTFkyBBhYWEhYmJisux/5swZoa2tLX755RcREREhpkyZInR1dcW1a9fyOXnhou5+7tOnjwgICBBXrlwRN2/eFAMGDBDm5ubiyZMn+Zy8cFF3P2d4+PChsLOzE82bNxddu3bNn7CFmLr7OSUlRdSvX1906NBBnD59Wjx8+FAcP35chIeH53PywkXd/bx161ahr68vtm7dKh4+fCgOHTokbG1txejRo/M5eeFy4MABMXnyZLF7924BQOzZs+ej/R88eCCMjIyEr6+viIiIEEuXLhXa2toiNDQ0T3OyuFFDw4YNxYgRI5TLcrlclClTRvj7+2fZ393dXXTs2FGlrVGjRuK7777L05yFnbr7+b/S09OFqamp2LhxY15FLBJys5/T09NFkyZNxNq1a4WXlxeLmxxQdz+vWLFCODo6itTU1PyKWCSou59HjBgh2rRpo9Lm6+srmjZtmqc5i5KcFDfjxo0TNWrUUGnz8PAQbm5ueZhMCB6WyqHU1FRcvnwZrq6uyjYtLS24urri3LlzWa5z7tw5lf4A4Obmlm1/yt1+/q/3798jLS0NJUuWzKuYhV5u9/NPP/0EKysrDBo0KD9iFnq52c8hISFo3LgxRowYAWtra9SsWROzZ8+GXC7Pr9iFTm72c5MmTXD58mXloasHDx7gwIED6NChQ75kLi6k+hwsdjfOzK3Y2FjI5XJYW1urtFtbW+PWrVtZrhMdHZ1l/+jo6DzLWdjlZj//1/jx41GmTJlMP1D0/3Kzn0+fPo1169YhPDw8HxIWDbnZzw8ePMBff/2Fvn374sCBA7h37x6GDx+OtLQ0+Pn55UfsQic3+7lPnz6IjY1Fs2bNIIRAeno6hg4dikmTJuVH5GIju8/B+Ph4JCUlwdDQME9elyM3VKTMmTMH27dvx549e2BgYCB1nCIjISEB/fr1w5o1a1C6dGmp4xRpCoUCVlZWWL16NVxcXODh4YHJkydj5cqVUkcrUo4fP47Zs2dj+fLlCAsLw+7du7F//378/PPPUkcjDeDITQ6VLl0a2traiImJUWmPiYmBjY1NluvY2Nio1Z9yt58z/Prrr5gzZw6OHDmC2rVr52XMQk/d/Xz//n1ERkaic+fOyjaFQgEA0NHRwe3bt+Hk5JS3oQuh3Hw/29raQldXF9ra2sq2atWqITo6GqmpqdDT08vTzIVRbvbz1KlT0a9fPwwePBgAUKtWLSQmJuLbb7/F5MmToaXFv/01IbvPQTMzszwbtQE4cpNjenp6cHFxwdGjR5VtCoUCR48eRePGjbNcp3Hjxir9AeDw4cPZ9qfc7WcA+OWXX/Dzzz8jNDQU9evXz4+ohZq6+7lq1aq4du0awsPDlY8uXbqgdevWCA8Ph729fX7GLzRy8/3ctGlT3Lt3T1k8AsCdO3dga2vLwiYbudnP79+/z1TAZBSUgrdc1BjJPgfzdLpyEbN9+3ahr68vAgMDRUREhPj222+FhYWFiI6OFkII0a9fPzFhwgRl/zNnzggdHR3x66+/ips3bwo/Pz+eCp4D6u7nOXPmCD09PbFz507x/Plz5SMhIUGqt1AoqLuf/4tnS+WMuvs5KipKmJqaCh8fH3H79m3xxx9/CCsrKzFz5kyp3kKhoO5+9vPzE6ampuK3334TDx48EH/++adwcnIS7u7uUr2FQiEhIUFcuXJFXLlyRQAQCxYsEFeuXBGPHj0SQggxYcIE0a9fP2X/jFPBx44dK27evCkCAgJ4KnhBtHTpUlGuXDmhp6cnGjZsKM6fP698rmXLlsLLy0ulf3BwsKhcubLQ09MTNWrUEPv378/nxIWTOvu5fPnyAkCmh5+fX/4HL2TU/X7+NxY3Oafufj579qxo1KiR0NfXF46OjmLWrFkiPT09n1MXPurs57S0NDF9+nTh5OQkDAwMhL29vRg+fLh48+ZN/gcvRI4dO5bl79uMfevl5SVatmyZaR1nZ2ehp6cnHB0dxYYNG/I8p0wIjr8RERFR0cE5N0RERFSksLghIiKiIoXFDRERERUpLG6IiIioSGFxQ0REREUKixsiIiIqUljcEBERUZHC4oaIVAQGBsLCwkLqGLkmk8mwd+/ej/YZMGAAunXrli95iCj/sbghKoIGDBgAmUyW6XHv3j2poyEwMFCZR0tLC2XLloW3tzdevHihke0/f/4cX331FQAgMjISMpkM4eHhKn0WL16MwMBAjbxedqZPn658n9ra2rC3t8e3336L169fq7UdFmJE6uNdwYmKqPbt22PDhg0qbZaWlhKlUWVmZobbt29DoVDg6tWr8Pb2xrNnz3Do0KHP3van7h4PAObm5p/9OjlRo0YNHDlyBHK5HDdv3sTAgQMRFxeHoKCgfHl9ouKKIzdERZS+vj5sbGxUHtra2liwYAFq1aoFY2Nj2NvbY/jw4Xj37l2227l69Spat24NU1NTmJmZwcXFBZcuXVI+f/r0aTRv3hyGhoawt7fH999/j8TExI9mk8lksLGxQZkyZfDVV1/h+++/x5EjR5CUlASFQoGffvoJZcuWhb6+PpydnREaGqpcNzU1FT4+PrC1tYWBgQHKly8Pf39/lW1nHJaqUKECAKBu3bqQyWRo1aoVANXRkNWrV6NMmTIqd+EGgK5du2LgwIHK5d9//x316tWDgYEBHB0dMWPGDKSnp3/0fero6MDGxgZ2dnZwdXVFr169cPjwYeXzcrkcgwYNQoUKFWBoaIgqVapg8eLFyuenT5+OjRs34vfff1eOAh0/fhwA8PjxY7i7u8PCwgIlS5ZE165dERkZ+dE8RMUFixuiYkZLSwtLlizBjRs3sHHjRvz1118YN25ctv379u2LsmXL4uLFi7h8+TImTJgAXV1dAMD9+/fRvn179OjRA//88w+CgoJw+vRp+Pj4qJXJ0NAQCoUC6enpWLx4MebPn49ff/0V//zzD9zc3NClSxfcvXsXALBkyRKEhIQgODgYt2/fxtatW+Hg4JDldv/++28AwJEjR/D8+XPs3r07U59evXrh1atXOHbsmLLt9evXCA0NRd++fQEAp06dQv/+/TFq1ChERERg1apVCAwMxKxZs3L8HiMjI3Ho0CHo6ekp2xQKBcqWLYsdO3YgIiIC06ZNw6RJkxAcHAwAGDNmDNzd3dG+fXs8f/4cz58/R5MmTZCWlgY3NzeYmpri1KlTOHPmDExMTNC+fXukpqbmOBNRkZXnt+Ykonzn5eUltLW1hbGxsfLRs2fPLPvu2LFDlCpVSrm8YcMGYW5urlw2NTUVgYGBWa47aNAg8e2336q0nTp1SmhpaYmkpKQs1/nv9u/cuSMqV64s6tevL4QQokyZMmLWrFkq6zRo0EAMHz5cCCHEyJEjRZs2bYRCochy+wDEnj17hBBCPHz4UAAQV65cUenz3zuad+3aVQwcOFC5vGrVKlGmTBkhl8uFEEK0bdtWzJ49W2UbmzdvFra2tllmEEIIPz8/oaWlJYyNjYWBgYHy7skLFizIdh0hhBgxYoTo0aNHtlkzXrtKlSoq+yAlJUUYGhqKQ4cOfXT7RMUB59wQFVGtW7fGihUrlMvGxsYAPoxi+Pv749atW4iPj0d6ejqSk5Px/v17GBkZZdqOr68vBg8ejM2bNysPrTg5OQH4cMjqn3/+wdatW5X9hRBQKBR4+PAhqlWrlmW2uLg4mJiYQKFQIDk5Gc2aNcPatWsRHx+PZ8+eoWnTpir9mzZtiqtXrwL4cEjpyy+/RJUqVdC+fXt06tQJ7dq1+6x91bdvXwwZMgTLly+Hvr4+tm7dCk9PT2hpaSnf55kzZ1RGauRy+Uf3GwBUqVIFISEhSE5OxpYtWxAeHo6RI0eq9AkICMD69esRFRWFpKQkpKamwtnZ+aN5r169inv37sHU1FSlPTk5Gffv38/FHiAqWljcEBVRxsbGqFixokpbZGQkOnXqhGHDhmHWrFkoWbIkTp8+jUGDBiE1NTXLD+np06ejT58+2L9/Pw4ePAg/Pz9s374dX3/9Nd69e4fvvvsO33//fab1ypUrl202U1NThIWFQUtLC7a2tjA0NAQAxMfHf/J91atXDw8fPsTBgwdx5MgRuLu7w9XVFTt37vzkutnp3LkzhBDYv38/GjRogFOnTmHhwoXK59+9e4cZM2age/fumdY1MDDIdrt6enrKr8GcOXPQsWNHzJgxAz///DMAYPv27RgzZgzmz5+Pxo0bw9TUFPPmzcOFCxc+mvfdu3dwcXFRKSozFJRJ40RSYnFDVIxcvnwZCoUC8+fPV45KZMzv+JjKlSujcuXKGD16NHr37o0NGzbg66+/Rr169RAREZGpiPoULS2tLNcxMzNDmTJlcObMGbRs2VLZfubMGTRs2FCln4eHBzw8PNCzZ0+0b98er1+/RsmSJVW2lzG/RS6XfzSPgYEBunfvjq1bt+LevXuoUqUK6tWrp3y+Xr16uH37ttrv87+mTJmCNm3aYNiwYcr32aRJEwwfPlzZ578jL3p6epny16tXD0FBQbCysoKZmdlnZSIqijihmKgYqVixItLS0rB06VI8ePAAmzdvxsqVK7Ptn5SUBB8fHxw/fhyPHj3CmTNncPHiReXhpvHjx+Ps2bPw8fFBeHg47t69i99//13tCcX/NnbsWMydOxdBQUG4ffs2JkyYgPDwcIwaNQoAsGDBAvz222+4desW7ty5gx07dsDGxibLCw9aWVnB0NAQoaGhiImJQVxcXLav27dvX+zfvx/r169XTiTOMG3aNGzatAkzZszAjRs3cPPmTWzfvh1TpkxR6701btwYtWvXxuzZswEAlSpVwqVLl3Do0CHcuXMHU6dOxcWLF1XWcXBwwD///IPbt28jNjYWaWlp6Nu3L0qXLo2uXbvi1KlTePjwIY4fP47vv/8eT548USsTUZEk9aQfItK8rCahZliwYIGwtbUVhoaGws3NTWzatEkAEG/evBFCqE74TUlJEZ6ensLe3l7o6emJMmXKCB8fH5XJwn///bf48ssvhYmJiTA2Nha1a9fONCH43/47ofi/5HK5mD59urCzsxO6urqiTp064uDBg8rnV69eLZydnYWxsbEwMzMTbdu2FWFhYcrn8a8JxUIIsWbNGmFvby+0tLREy5Yts90/crlc2NraCgDi/v37mXKFhoaKJk2aCENDQ2FmZiYaNmwoVq9ene378PPzE3Xq1MnU/ttvvwl9fX0RFRUlkpOTxYABA4S5ubmwsLAQw4YNExMmTFBZ78WLF8r9C0AcO3ZMCCHE8+fPRf/+/UXp0qWFvr6+cHR0FEOGDBFxcXHZZiIqLmRCCCFteUVERESkOTwsRUREREUKixsiIiIqUljcEBERUZHC4oaIiIiKFBY3REREVKSwuCEiIqIihcUNERERFSksboiIiKhIYXFDRERERQqLGyIiIipSWNwQERFRkcLihoiIiIqU/wOQ0NWT4U/p7wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Add predictions to test set\n",
    "df_test[\"true_label\"] = true_labels\n",
    "df_test[\"pred_label\"] = pred_labels\n",
    "df_test[\"prob_rel\"] = pred_probs[:, 1]  # class 1 = RELATIONSHIP\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(true_labels, pred_probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(true_labels, pred_probs[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label=\"Precision-Recall curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0f4f909-e682-495c-8f60-1b0d115020ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment-bert-first-model/tokenizer_config.json',\n",
       " './sentiment-bert-first-model/special_tokens_map.json',\n",
       " './sentiment-bert-first-model/vocab.txt',\n",
       " './sentiment-bert-first-model/added_tokens.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./sentiment-bert-first-model\")\n",
    "tokenizer.save_pretrained(\"./sentiment-bert-first-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff1766fa-605c-4a83-a092-2565fa7096bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already set up earlier with CustomTrainer and `compute_metrics`\n",
    "# Define a model_init function\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def model_init():\n",
    "    return BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", num_labels=2\n",
    "    )\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"eval_accuracy\": accuracy_score(labels, preds),\n",
    "        \"eval_precision_macro\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"eval_recall_macro\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"eval_f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "# Define the hyperparameter space function that uses the trial object\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
    "        # \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 3, 6),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3)\n",
    "    }\n",
    "\n",
    "def compute_objective(metrics):\n",
    "    return metrics[\"eval_f1_macro\"] \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",                 # Folder to save checkpoints and logs\n",
    "    num_train_epochs=4,                     # Number of full passes through the training set\n",
    "    per_device_train_batch_size=16,         # Batch size per GPU/CPU for training\n",
    "    eval_strategy=IntervalStrategy.EPOCH,            # Run evaluation after each training epoch\n",
    "    save_strategy=IntervalStrategy.EPOCH,                  # Save model checkpoint after each epoch\n",
    "    logging_dir=None,                   # Directory for storing logs (TensorBoard, etc.)\n",
    "    logging_steps=10,                       # Log metrics every 10 steps (if logging_strategy=\"steps\")\n",
    "    load_best_model_at_end=True,            # Restore the best model (lowest eval loss) at the end\n",
    "    metric_for_best_model=\"eval_f1_macro\",      # Metric to monitor for choosing the best model\n",
    "    save_total_limit =1, \n",
    "    greater_is_better=True, \n",
    "    report_to = \"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "085be70f-ec60-464d-9913-8c406932efd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[I 2025-06-16 13:36:03,076] A new study created in memory with name: no-name-a650934c-bb18-424a-b900-3201056c878f\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1544' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1544/1544 04:22, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.096094</td>\n",
       "      <td>0.961393</td>\n",
       "      <td>0.962225</td>\n",
       "      <td>0.953702</td>\n",
       "      <td>0.957707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.093254</td>\n",
       "      <td>0.969720</td>\n",
       "      <td>0.964913</td>\n",
       "      <td>0.969897</td>\n",
       "      <td>0.967305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.094638</td>\n",
       "      <td>0.968963</td>\n",
       "      <td>0.964616</td>\n",
       "      <td>0.968382</td>\n",
       "      <td>0.966443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.092681</td>\n",
       "      <td>0.967449</td>\n",
       "      <td>0.963704</td>\n",
       "      <td>0.965816</td>\n",
       "      <td>0.964742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 13:40:26,584] Trial 0 finished with value: 0.9647423941008699 and parameters: {'learning_rate': 1.0724049175708623e-05, 'weight_decay': 0.1523630956894824}. Best is trial 0 with value: 0.9647423941008699.\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1544' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1544/1544 04:22, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.090853</td>\n",
       "      <td>0.966692</td>\n",
       "      <td>0.963450</td>\n",
       "      <td>0.964301</td>\n",
       "      <td>0.963873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.103583</td>\n",
       "      <td>0.965178</td>\n",
       "      <td>0.959092</td>\n",
       "      <td>0.966351</td>\n",
       "      <td>0.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.098245</td>\n",
       "      <td>0.968206</td>\n",
       "      <td>0.965091</td>\n",
       "      <td>0.965945</td>\n",
       "      <td>0.965515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.098563</td>\n",
       "      <td>0.968206</td>\n",
       "      <td>0.965091</td>\n",
       "      <td>0.965945</td>\n",
       "      <td>0.965515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 13:44:50,425] Trial 1 finished with value: 0.9655151409676296 and parameters: {'learning_rate': 2.261661144028213e-05, 'weight_decay': 0.09626749578591533}. Best is trial 1 with value: 0.9655151409676296.\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1544' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1544/1544 04:22, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>0.102816</td>\n",
       "      <td>0.959879</td>\n",
       "      <td>0.962582</td>\n",
       "      <td>0.950212</td>\n",
       "      <td>0.955873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.960362</td>\n",
       "      <td>0.966480</td>\n",
       "      <td>0.963267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.103171</td>\n",
       "      <td>0.966692</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.967071</td>\n",
       "      <td>0.964068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.095908</td>\n",
       "      <td>0.968963</td>\n",
       "      <td>0.964269</td>\n",
       "      <td>0.968844</td>\n",
       "      <td>0.966473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 13:49:14,155] Trial 2 finished with value: 0.9664729321590821 and parameters: {'learning_rate': 2.8610106381072803e-05, 'weight_decay': 0.15669653052137436}. Best is trial 2 with value: 0.9664729321590821.\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1544' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1544/1544 04:22, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.094962</td>\n",
       "      <td>0.968206</td>\n",
       "      <td>0.963626</td>\n",
       "      <td>0.967791</td>\n",
       "      <td>0.965640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.118770</td>\n",
       "      <td>0.962907</td>\n",
       "      <td>0.956233</td>\n",
       "      <td>0.964578</td>\n",
       "      <td>0.960106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.095642</td>\n",
       "      <td>0.968963</td>\n",
       "      <td>0.964973</td>\n",
       "      <td>0.967921</td>\n",
       "      <td>0.966413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.093547</td>\n",
       "      <td>0.968963</td>\n",
       "      <td>0.964616</td>\n",
       "      <td>0.968382</td>\n",
       "      <td>0.966443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 13:53:37,431] Trial 3 finished with value: 0.9664429363871184 and parameters: {'learning_rate': 1.9257922496933035e-05, 'weight_decay': 0.08168687530643723}. Best is trial 2 with value: 0.9664729321590821.\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1544' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1544/1544 04:22, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.095791</td>\n",
       "      <td>0.964421</td>\n",
       "      <td>0.958135</td>\n",
       "      <td>0.965760</td>\n",
       "      <td>0.961702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.108256</td>\n",
       "      <td>0.967449</td>\n",
       "      <td>0.962985</td>\n",
       "      <td>0.966739</td>\n",
       "      <td>0.964806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.119355</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.961706</td>\n",
       "      <td>0.964634</td>\n",
       "      <td>0.963136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.115655</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.961014</td>\n",
       "      <td>0.965557</td>\n",
       "      <td>0.963202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 13:58:00,738] Trial 4 finished with value: 0.963201998711188 and parameters: {'learning_rate': 4.692960442630243e-05, 'weight_decay': 0.011335295980089921}. Best is trial 2 with value: 0.9664729321590821.\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1158' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1158/1544 03:11 < 01:04, 6.02 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>0.966692</td>\n",
       "      <td>0.963840</td>\n",
       "      <td>0.963840</td>\n",
       "      <td>0.963840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.103180</td>\n",
       "      <td>0.966692</td>\n",
       "      <td>0.961016</td>\n",
       "      <td>0.967533</td>\n",
       "      <td>0.964099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.093382</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.962440</td>\n",
       "      <td>0.963710</td>\n",
       "      <td>0.963069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:01:33,079] Trial 5 pruned. \n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='772' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 772/1544 02:07 < 02:07, 6.05 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.960683</td>\n",
       "      <td>0.966018</td>\n",
       "      <td>0.963235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.112074</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.960683</td>\n",
       "      <td>0.966018</td>\n",
       "      <td>0.963235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:03:58,448] Trial 6 pruned. \n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='386' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 386/1544 01:02 < 03:07, 6.17 it/s, Epoch 1/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.099753</td>\n",
       "      <td>0.961393</td>\n",
       "      <td>0.962719</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.957665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:05:17,482] Trial 7 pruned. \n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1159' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1159/1544 03:07 < 01:02, 6.16 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.080791</td>\n",
       "      <td>0.968206</td>\n",
       "      <td>0.963626</td>\n",
       "      <td>0.967791</td>\n",
       "      <td>0.965640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.136216</td>\n",
       "      <td>0.964421</td>\n",
       "      <td>0.958135</td>\n",
       "      <td>0.965760</td>\n",
       "      <td>0.961702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.960683</td>\n",
       "      <td>0.966018</td>\n",
       "      <td>0.963235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-16 14:08:50,271] Trial 8 failed with parameters: {'learning_rate': 4.641901189244264e-05, 'weight_decay': 0.2839856342153951} because of the following error: OSError(122, 'Disk quota exceeded').\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/site-packages/transformers/integrations/integration_utils.py\", line 248, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py\", line 2123, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py\", line 2573, in _inner_training_loop\n",
      "    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py\", line 3007, in _maybe_log_save_evaluate\n",
      "    self._save_checkpoint(model, trial, metrics=metrics)\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py\", line 3097, in _save_checkpoint\n",
      "    self.save_model(output_dir, _internal_call=True)\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py\", line 3730, in save_model\n",
      "    self._save(output_dir)\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py\", line 3811, in _save\n",
      "    os.makedirs(output_dir, exist_ok=True)\n",
      "  File \"/cluster/home/hlee37/condaenv/torch_env/lib/python3.8/os.py\", line 223, in makedirs\n",
      "    mkdir(name, mode)\n",
      "OSError: [Errno 122] Disk quota exceeded: './results/run-8/checkpoint-1158'\n",
      "[W 2025-06-16 14:08:50,274] Trial 8 failed with value None.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded: './results/run-8/checkpoint-1158'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model_init\u001b[38;5;241m=\u001b[39mmodel_init,                     \u001b[38;5;66;03m# <‚Äî‚Äî pass it here\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhp_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptuna_hp_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_objective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py:3473\u001b[0m, in \u001b[0;36mTrainer.hyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   3470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_name \u001b[38;5;241m=\u001b[39m hp_name\n\u001b[1;32m   3471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_objective \u001b[38;5;241m=\u001b[39m default_compute_objective \u001b[38;5;28;01mif\u001b[39;00m compute_objective \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m compute_objective\n\u001b[0;32m-> 3473\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_search_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_run\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/hyperparameter_search.py:72\u001b[0m, in \u001b[0;36mOptunaBackend.run\u001b[0;34m(self, trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer, n_trials: \u001b[38;5;28mint\u001b[39m, direction: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_hp_search_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/integrations/integration_utils.py:261\u001b[0m, in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m directions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m direction\n\u001b[1;32m    260\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39mdirection, directions\u001b[38;5;241m=\u001b[39mdirections, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 261\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    263\u001b[0m     best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/integrations/integration_utils.py:248\u001b[0m, in \u001b[0;36mrun_hp_search_optuna.<locals>._objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    246\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py:2573\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2573\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2577\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py:3007\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   3004\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3007\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py:3097\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   3095\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3096\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 3097\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   3101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(output_dir)\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py:3730\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3727\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   3729\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3730\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   3733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/site-packages/transformers/trainer.py:3811\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_dir: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, state_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m# If we are executing this function, we are the process zero, so we don't check for that.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m output_dir \u001b[38;5;28;01mif\u001b[39;00m output_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_dir\n\u001b[0;32m-> 3811\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3812\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving model checkpoint to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3814\u001b[0m     supported_classes \u001b[38;5;241m=\u001b[39m (PreTrainedModel,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_peft_available() \u001b[38;5;28;01melse\u001b[39;00m (PreTrainedModel, PeftModel)\n",
      "File \u001b[0;32m~/condaenv/torch_env/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded: './results/run-8/checkpoint-1158'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,                     # <‚Äî‚Äî pass it here\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    hp_space=optuna_hp_space,\n",
    "    compute_objective=compute_objective,\n",
    "    direction=\"maximize\",\n",
    "    n_trials=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db1d2d1c-ad05-473f-a8f2-e1fcc63b69b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-0/checkpoint-772 ‚Üí eval_f1_macro: 0.9673\n",
      "run-1/checkpoint-1158 ‚Üí eval_f1_macro: 0.9655\n",
      "run-2/checkpoint-1544 ‚Üí eval_f1_macro: 0.9665\n",
      "run-3/checkpoint-1544 ‚Üí eval_f1_macro: 0.9664\n",
      "run-4/checkpoint-772 ‚Üí eval_f1_macro: 0.9648\n",
      "run-5/checkpoint-772 ‚Üí eval_f1_macro: 0.9641\n",
      "run-6/checkpoint-386 ‚Üí eval_f1_macro: 0.9632\n",
      "\n",
      "üèÜ Best checkpoint: ./results/run-0/checkpoint-772 with eval_f1_macro: 0.9673\n"
     ]
    }
   ],
   "source": [
    "# Set metric\n",
    "metric_to_use = \"eval_f1_macro\"\n",
    "\n",
    "# Define base path for all runs\n",
    "base_path = \"./results\"\n",
    "\n",
    "best_score = -1\n",
    "best_run = None\n",
    "\n",
    "# Loop over run-* folders\n",
    "for run_dir in sorted(os.listdir(base_path)):\n",
    "    run_path = os.path.join(base_path, run_dir)\n",
    "    if os.path.isdir(run_path) and re.match(r\"run-\\d+\", run_dir):\n",
    "        try:\n",
    "            # Find latest checkpoint-* folder inside run_dir\n",
    "            checkpoints = [f for f in os.listdir(run_path) if f.startswith(\"checkpoint-\")]\n",
    "            if not checkpoints:\n",
    "                continue\n",
    "            latest_ckpt = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))[-1]\n",
    "            model_path = os.path.join(run_path, latest_ckpt)\n",
    "\n",
    "            # Load model and evaluate\n",
    "            model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "            trainer.model = model.to(trainer.args.device)\n",
    "            metrics = trainer.evaluate(eval_dataset=val_ds)\n",
    "\n",
    "            score = metrics.get(metric_to_use)\n",
    "            print(f\"{run_dir}/{latest_ckpt} ‚Üí {metric_to_use}: {score:.4f}\")\n",
    "\n",
    "            if score is not None and score > best_score:\n",
    "                best_score = score\n",
    "                best_run = model_path\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping {run_dir}: {e}\")\n",
    "\n",
    "print(f\"\\nüèÜ Best checkpoint: {best_run} with {metric_to_use}: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87d9d0fc-6894-4ea8-a6a5-d049686cb698",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"learning_rate\": 0.000010724049175708623,\n",
    "    \"weight_decay\": 0.1523630956894824\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36f1afd7-50bb-4ef0-be98-5cc5033c57e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1544' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1544/1544 04:21, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.158352</td>\n",
       "      <td>0.956094</td>\n",
       "      <td>0.959701</td>\n",
       "      <td>0.944948</td>\n",
       "      <td>0.951588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.102127</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.962440</td>\n",
       "      <td>0.963710</td>\n",
       "      <td>0.963069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.106473</td>\n",
       "      <td>0.966692</td>\n",
       "      <td>0.963450</td>\n",
       "      <td>0.964301</td>\n",
       "      <td>0.963873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.108748</td>\n",
       "      <td>0.965935</td>\n",
       "      <td>0.962823</td>\n",
       "      <td>0.963249</td>\n",
       "      <td>0.963035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1544, training_loss=0.04532681409284048, metrics={'train_runtime': 261.9959, 'train_samples_per_second': 94.093, 'train_steps_per_second': 5.893, 'total_flos': 2508340468502880.0, 'train_loss': 0.04532681409284048, 'epoch': 4.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_params = best_run.hyperparameters\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./best-results\",                             # you can change this\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size= 16,\n",
    "    eval_strategy=IntervalStrategy.EPOCH,            # Run evaluation after each training epoch\n",
    "    save_strategy=IntervalStrategy.EPOCH,                  # Save model checkpoint after each epoch\n",
    "    logging_dir=None,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model=\"eval_f1_macro\",\n",
    "    weight_decay=best_params[\"weight_decay\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    save_total_limit=1, \n",
    "    report_to=\"none\"                                         # turn off wandb if needed\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"./results/run-0/checkpoint-772\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model= model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86e8f629-8e73-4cc0-8fe0-c0ee325a094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='166' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/166 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.967448902346707, 'eval_precision_macro': 0.9652682118544249, 'eval_recall_macro': 0.9639691427149434, 'eval_f1_macro': 0.9646123607230409, 'eval_loss': 0.10811550915241241, 'eval_runtime': 4.0429, 'eval_samples_per_second': 326.748, 'eval_steps_per_second': 41.06, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate(eval_dataset=test_ds)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c50ba844-3dc6-4b76-a7f0-b9a8372ff83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./best-sentiment-bert/tokenizer_config.json',\n",
       " './best-sentiment-bert/special_tokens_map.json',\n",
       " './best-sentiment-bert/vocab.txt',\n",
       " './best-sentiment-bert/added_tokens.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save final model\n",
    "trainer.save_model(\"./best-sentiment-bert\")\n",
    "tokenizer.save_pretrained(\"./best-sentiment-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21700b3d-9e73-4e02-ac80-9defb1208f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
